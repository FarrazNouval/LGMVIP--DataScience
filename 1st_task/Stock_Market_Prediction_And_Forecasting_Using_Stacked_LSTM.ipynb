{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNecv6dTzKtV/VqR3uoPgHc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FarrazNouval/LGMVIP--DataScience/blob/main/Stock_Market_Prediction_And_Forecasting_Using_Stacked_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><strong><center>Stock Market Prediction And Forecasting Using Stacked LSTM</center></strong></h1>\n"
      ],
      "metadata": {
        "id": "8TK5XeK8VUeQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. import modules\n"
      ],
      "metadata": {
        "id": "xJ99WHnsXR8v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "5OsSjnCGVHzT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.layers import LSTM, Dense, Dropout, Input\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load The Dataset"
      ],
      "metadata": {
        "id": "9mrkx9Zu4MOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('/content/NSE-TATAGLOBAL.csv')\n",
        "dataset.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qgtRO1usYLPD",
        "outputId": "c57f4646-b759-4329-b93d-c2517901bb27"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date    Open    High     Low    Last   Close  Total Trade Quantity  \\\n",
              "0  2018-09-28  234.05  235.95  230.20  233.50  233.75               3069914   \n",
              "1  2018-09-27  234.55  236.80  231.10  233.80  233.25               5082859   \n",
              "2  2018-09-26  240.00  240.00  232.50  235.00  234.25               2240909   \n",
              "3  2018-09-25  233.30  236.75  232.00  236.25  236.10               2349368   \n",
              "4  2018-09-24  233.55  239.20  230.75  234.00  233.30               3423509   \n",
              "\n",
              "   Turnover (Lacs)  \n",
              "0          7162.35  \n",
              "1         11859.95  \n",
              "2          5248.60  \n",
              "3          5503.90  \n",
              "4          7999.55  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7aee916b-c62c-4f94-9df6-0ed790f9f512\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Last</th>\n",
              "      <th>Close</th>\n",
              "      <th>Total Trade Quantity</th>\n",
              "      <th>Turnover (Lacs)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-09-28</td>\n",
              "      <td>234.05</td>\n",
              "      <td>235.95</td>\n",
              "      <td>230.20</td>\n",
              "      <td>233.50</td>\n",
              "      <td>233.75</td>\n",
              "      <td>3069914</td>\n",
              "      <td>7162.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-09-27</td>\n",
              "      <td>234.55</td>\n",
              "      <td>236.80</td>\n",
              "      <td>231.10</td>\n",
              "      <td>233.80</td>\n",
              "      <td>233.25</td>\n",
              "      <td>5082859</td>\n",
              "      <td>11859.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-09-26</td>\n",
              "      <td>240.00</td>\n",
              "      <td>240.00</td>\n",
              "      <td>232.50</td>\n",
              "      <td>235.00</td>\n",
              "      <td>234.25</td>\n",
              "      <td>2240909</td>\n",
              "      <td>5248.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-09-25</td>\n",
              "      <td>233.30</td>\n",
              "      <td>236.75</td>\n",
              "      <td>232.00</td>\n",
              "      <td>236.25</td>\n",
              "      <td>236.10</td>\n",
              "      <td>2349368</td>\n",
              "      <td>5503.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-09-24</td>\n",
              "      <td>233.55</td>\n",
              "      <td>239.20</td>\n",
              "      <td>230.75</td>\n",
              "      <td>234.00</td>\n",
              "      <td>233.30</td>\n",
              "      <td>3423509</td>\n",
              "      <td>7999.55</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7aee916b-c62c-4f94-9df6-0ed790f9f512')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7aee916b-c62c-4f94-9df6-0ed790f9f512 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7aee916b-c62c-4f94-9df6-0ed790f9f512');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Inspect The Dataset"
      ],
      "metadata": {
        "id": "YCzSJsa14S0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.describe()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "aTegg3eCY163",
        "outputId": "43ed686d-b960-4cd1-e544-1b198bde8f6e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Open         High          Low         Last       Close  \\\n",
              "count  2035.000000  2035.000000  2035.000000  2035.000000  2035.00000   \n",
              "mean    149.713735   151.992826   147.293931   149.474251   149.45027   \n",
              "std      48.664509    49.413109    47.931958    48.732570    48.71204   \n",
              "min      81.100000    82.800000    80.000000    81.000000    80.95000   \n",
              "25%     120.025000   122.100000   118.300000   120.075000   120.05000   \n",
              "50%     141.500000   143.400000   139.600000   141.100000   141.25000   \n",
              "75%     157.175000   159.400000   155.150000   156.925000   156.90000   \n",
              "max     327.700000   328.750000   321.650000   325.950000   325.75000   \n",
              "\n",
              "       Total Trade Quantity  Turnover (Lacs)  \n",
              "count          2.035000e+03      2035.000000  \n",
              "mean           2.335681e+06      3899.980565  \n",
              "std            2.091778e+06      4570.767877  \n",
              "min            3.961000e+04        37.040000  \n",
              "25%            1.146444e+06      1427.460000  \n",
              "50%            1.783456e+06      2512.030000  \n",
              "75%            2.813594e+06      4539.015000  \n",
              "max            2.919102e+07     55755.080000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-08ecaa25-13f0-4d7a-9bd7-8ee0c431fadb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Last</th>\n",
              "      <th>Close</th>\n",
              "      <th>Total Trade Quantity</th>\n",
              "      <th>Turnover (Lacs)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2035.000000</td>\n",
              "      <td>2035.000000</td>\n",
              "      <td>2035.000000</td>\n",
              "      <td>2035.000000</td>\n",
              "      <td>2035.00000</td>\n",
              "      <td>2.035000e+03</td>\n",
              "      <td>2035.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>149.713735</td>\n",
              "      <td>151.992826</td>\n",
              "      <td>147.293931</td>\n",
              "      <td>149.474251</td>\n",
              "      <td>149.45027</td>\n",
              "      <td>2.335681e+06</td>\n",
              "      <td>3899.980565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>48.664509</td>\n",
              "      <td>49.413109</td>\n",
              "      <td>47.931958</td>\n",
              "      <td>48.732570</td>\n",
              "      <td>48.71204</td>\n",
              "      <td>2.091778e+06</td>\n",
              "      <td>4570.767877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>81.100000</td>\n",
              "      <td>82.800000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>80.95000</td>\n",
              "      <td>3.961000e+04</td>\n",
              "      <td>37.040000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>120.025000</td>\n",
              "      <td>122.100000</td>\n",
              "      <td>118.300000</td>\n",
              "      <td>120.075000</td>\n",
              "      <td>120.05000</td>\n",
              "      <td>1.146444e+06</td>\n",
              "      <td>1427.460000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>141.500000</td>\n",
              "      <td>143.400000</td>\n",
              "      <td>139.600000</td>\n",
              "      <td>141.100000</td>\n",
              "      <td>141.25000</td>\n",
              "      <td>1.783456e+06</td>\n",
              "      <td>2512.030000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>157.175000</td>\n",
              "      <td>159.400000</td>\n",
              "      <td>155.150000</td>\n",
              "      <td>156.925000</td>\n",
              "      <td>156.90000</td>\n",
              "      <td>2.813594e+06</td>\n",
              "      <td>4539.015000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>327.700000</td>\n",
              "      <td>328.750000</td>\n",
              "      <td>321.650000</td>\n",
              "      <td>325.950000</td>\n",
              "      <td>325.75000</td>\n",
              "      <td>2.919102e+07</td>\n",
              "      <td>55755.080000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-08ecaa25-13f0-4d7a-9bd7-8ee0c431fadb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-08ecaa25-13f0-4d7a-9bd7-8ee0c431fadb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-08ecaa25-13f0-4d7a-9bd7-8ee0c431fadb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.info()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNAompMgY6n6",
        "outputId": "d36c46c8-1f72-4fff-b0a8-b5a9e6733876"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2035 entries, 0 to 2034\n",
            "Data columns (total 8 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   Date                  2035 non-null   object \n",
            " 1   Open                  2035 non-null   float64\n",
            " 2   High                  2035 non-null   float64\n",
            " 3   Low                   2035 non-null   float64\n",
            " 4   Last                  2035 non-null   float64\n",
            " 5   Close                 2035 non-null   float64\n",
            " 6   Total Trade Quantity  2035 non-null   int64  \n",
            " 7   Turnover (Lacs)       2035 non-null   float64\n",
            "dtypes: float64(6), int64(1), object(1)\n",
            "memory usage: 127.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Manipulate and Prepare The Dataset to Train The Model"
      ],
      "metadata": {
        "id": "Op-PNbR750Nu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"Date\"] = pd.to_datetime(dataset['Date'], format=\"%Y-%m-%d\")\n"
      ],
      "metadata": {
        "id": "Cpf6wPICY-ks"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWXy4-b9Z6sw",
        "outputId": "4c907751-db1b-4eb0-8eb7-feef06543054"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2035 entries, 0 to 2034\n",
            "Data columns (total 8 columns):\n",
            " #   Column                Non-Null Count  Dtype         \n",
            "---  ------                --------------  -----         \n",
            " 0   Date                  2035 non-null   datetime64[ns]\n",
            " 1   Open                  2035 non-null   float64       \n",
            " 2   High                  2035 non-null   float64       \n",
            " 3   Low                   2035 non-null   float64       \n",
            " 4   Last                  2035 non-null   float64       \n",
            " 5   Close                 2035 non-null   float64       \n",
            " 6   Total Trade Quantity  2035 non-null   int64         \n",
            " 7   Turnover (Lacs)       2035 non-null   float64       \n",
            "dtypes: datetime64[ns](1), float64(6), int64(1)\n",
            "memory usage: 127.3 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6N85RIukZ761",
        "outputId": "0d368aa5-20b6-46cc-ab35-85a80b40641e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Date    Open    High     Low    Last   Close  Total Trade Quantity  \\\n",
              "0 2018-09-28  234.05  235.95  230.20  233.50  233.75               3069914   \n",
              "1 2018-09-27  234.55  236.80  231.10  233.80  233.25               5082859   \n",
              "2 2018-09-26  240.00  240.00  232.50  235.00  234.25               2240909   \n",
              "3 2018-09-25  233.30  236.75  232.00  236.25  236.10               2349368   \n",
              "4 2018-09-24  233.55  239.20  230.75  234.00  233.30               3423509   \n",
              "\n",
              "   Turnover (Lacs)  \n",
              "0          7162.35  \n",
              "1         11859.95  \n",
              "2          5248.60  \n",
              "3          5503.90  \n",
              "4          7999.55  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-94547438-8ea9-4817-a8b1-e03dd1384221\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Last</th>\n",
              "      <th>Close</th>\n",
              "      <th>Total Trade Quantity</th>\n",
              "      <th>Turnover (Lacs)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-09-28</td>\n",
              "      <td>234.05</td>\n",
              "      <td>235.95</td>\n",
              "      <td>230.20</td>\n",
              "      <td>233.50</td>\n",
              "      <td>233.75</td>\n",
              "      <td>3069914</td>\n",
              "      <td>7162.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-09-27</td>\n",
              "      <td>234.55</td>\n",
              "      <td>236.80</td>\n",
              "      <td>231.10</td>\n",
              "      <td>233.80</td>\n",
              "      <td>233.25</td>\n",
              "      <td>5082859</td>\n",
              "      <td>11859.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-09-26</td>\n",
              "      <td>240.00</td>\n",
              "      <td>240.00</td>\n",
              "      <td>232.50</td>\n",
              "      <td>235.00</td>\n",
              "      <td>234.25</td>\n",
              "      <td>2240909</td>\n",
              "      <td>5248.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-09-25</td>\n",
              "      <td>233.30</td>\n",
              "      <td>236.75</td>\n",
              "      <td>232.00</td>\n",
              "      <td>236.25</td>\n",
              "      <td>236.10</td>\n",
              "      <td>2349368</td>\n",
              "      <td>5503.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-09-24</td>\n",
              "      <td>233.55</td>\n",
              "      <td>239.20</td>\n",
              "      <td>230.75</td>\n",
              "      <td>234.00</td>\n",
              "      <td>233.30</td>\n",
              "      <td>3423509</td>\n",
              "      <td>7999.55</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94547438-8ea9-4817-a8b1-e03dd1384221')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-94547438-8ea9-4817-a8b1-e03dd1384221 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-94547438-8ea9-4817-a8b1-e03dd1384221');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def to_lower(text):\n",
        "  low = text.lower()\n",
        "  text = ''\n",
        "  for i in low:\n",
        "    if i == \" \":\n",
        "      text += \"_\"\n",
        "    else:\n",
        "      text += i\n",
        "  \n",
        "  return text\n",
        "\n",
        "dataset.columns = dataset.columns.map(to_lower)\n",
        "dataset.head()\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "02WnXG4tadBK",
        "outputId": "5897d370-f4fb-4bfb-cd54-1c3d681b775b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        date    open    high     low    last   close  total_trade_quantity  \\\n",
              "0 2018-09-28  234.05  235.95  230.20  233.50  233.75               3069914   \n",
              "1 2018-09-27  234.55  236.80  231.10  233.80  233.25               5082859   \n",
              "2 2018-09-26  240.00  240.00  232.50  235.00  234.25               2240909   \n",
              "3 2018-09-25  233.30  236.75  232.00  236.25  236.10               2349368   \n",
              "4 2018-09-24  233.55  239.20  230.75  234.00  233.30               3423509   \n",
              "\n",
              "   turnover_(lacs)  \n",
              "0          7162.35  \n",
              "1         11859.95  \n",
              "2          5248.60  \n",
              "3          5503.90  \n",
              "4          7999.55  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b69cb7cf-7ee9-464a-a500-6c40c621b6a2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>last</th>\n",
              "      <th>close</th>\n",
              "      <th>total_trade_quantity</th>\n",
              "      <th>turnover_(lacs)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-09-28</td>\n",
              "      <td>234.05</td>\n",
              "      <td>235.95</td>\n",
              "      <td>230.20</td>\n",
              "      <td>233.50</td>\n",
              "      <td>233.75</td>\n",
              "      <td>3069914</td>\n",
              "      <td>7162.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-09-27</td>\n",
              "      <td>234.55</td>\n",
              "      <td>236.80</td>\n",
              "      <td>231.10</td>\n",
              "      <td>233.80</td>\n",
              "      <td>233.25</td>\n",
              "      <td>5082859</td>\n",
              "      <td>11859.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-09-26</td>\n",
              "      <td>240.00</td>\n",
              "      <td>240.00</td>\n",
              "      <td>232.50</td>\n",
              "      <td>235.00</td>\n",
              "      <td>234.25</td>\n",
              "      <td>2240909</td>\n",
              "      <td>5248.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-09-25</td>\n",
              "      <td>233.30</td>\n",
              "      <td>236.75</td>\n",
              "      <td>232.00</td>\n",
              "      <td>236.25</td>\n",
              "      <td>236.10</td>\n",
              "      <td>2349368</td>\n",
              "      <td>5503.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-09-24</td>\n",
              "      <td>233.55</td>\n",
              "      <td>239.20</td>\n",
              "      <td>230.75</td>\n",
              "      <td>234.00</td>\n",
              "      <td>233.30</td>\n",
              "      <td>3423509</td>\n",
              "      <td>7999.55</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b69cb7cf-7ee9-464a-a500-6c40c621b6a2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b69cb7cf-7ee9-464a-a500-6c40c621b6a2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b69cb7cf-7ee9-464a-a500-6c40c621b6a2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.plot(dataset['date'], dataset['turnover_(lacs)'], label='turnover_(lacs)')\n",
        "plt.xlabel('date')\n",
        "plt.ylabel('turnover');\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "nBLf-VN5daoZ",
        "outputId": "c781eb0e-2ab7-4ac9-f9e1-5d7d39883f9c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuEAAAE9CAYAAAClVLxbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAABzr0lEQVR4nO3dd5wU5f0H8M+ze41ejyLtABEEFRWkWFABFdSoiSUm9lhi1Kg/Ywy22CMp1mgssRsVGyoKijQB6b23o/c76t1xdXef3x87MzszOzM7e7dl9vi8Xy9e3M3Ozj47tzvznWe+z/cRUkoQEREREVHq+NLdACIiIiKiow2DcCIiIiKiFGMQTkRERESUYgzCiYiIiIhSjEE4EREREVGKMQgnIiIiIkqxrHQ3INVat24tCwoK0t0MIiIiIqrHFi1atE9KmW/3+FEXhBcUFGDhwoXpbgYRERER1WNCiK1OjzMdhYiIiIgoxRiEExERERGlGINwIiIiIqIUYxBORERERJRiDMKJiIiIiFKMQTgRERERUYoxCCciIiIiSjEG4UREREREKcYgnIiIiIgoxRiEExEREXnIoq0HUFYVSHczKMkYhBMRERF5xOHyGlz+2hzc9fHidDeFkoxBOBEREZFHVAWCAIBVu0rS3BJKNgbhRERERB4h090AShkG4UREREQeI9LdAEo6BuFERERERCnGIJyIiIjIIyTzUY4aDMKJiIiIiFKMQTgRERERUYoxCCciIiLyCKnURxEcmVnvMQgnIiIiIkoxBuFERERERCnGIJyIiIjIYwQrhdd7DMKJiIiIiFKMQTgRERGRR7BO+NGDQTgRERGRx7A6Sv3HIJyIiIiIKMUYhBMRERERpRiDcCIiIiKPYEr40YNBOBEREZHHMCW8/mMQTkRERESUYgzCiYiIiDxCskbhUYNBOBERERFRiiU1CBdCbBFCrBBCLBVCLFSWtRRCTBJCbFD+b6EsF0KIl4UQhUKI5UKIU3XbuUFZf4MQ4gbd8n7K9guV5zKFioiIiIg8LxU94edKKU+WUvZXfh8FYIqUsgeAKcrvADASQA/l320AXgPCQTuAxwAMBDAAwGNq4K6sc6vueSOS/3aIiIiIkkPNRmG/Yv2XjnSUSwG8r/z8PoDLdMs/kGFzATQXQrQHcAGASVLKA1LKgwAmARihPNZUSjlXhhOoPtBti4iIiIjIs5IdhEsAPwohFgkhblOWtZVS7lZ+3gOgrfJzBwDbdc/doSxzWr7DYjkRERERkadlJXn7Z0opdwoh2gCYJIRYq39QSimFEEkfBqxcANwGAJ07d072yxEREREROUpqT7iUcqfyfxGArxDO6d6rpJJA+b9IWX0ngE66p3dUljkt72ix3Kodb0op+0sp++fn59f1bRERERER1UnSgnAhRCMhRBP1ZwDnA1gJYBwAtcLJDQC+UX4eB+B6pUrKIACHlbSViQDOF0K0UAZkng9govJYiRBikFIV5XrdtoiIiIiIPCuZ6ShtAXyljO7NAvCxlPIHIcQCAJ8JIW4GsBXAVcr6EwBcCKAQQDmAmwBASnlACPEUgAXKek9KKQ8oP98B4D0ADQB8r/wjIiIiymgsjlL/JS0Il1JuAtDXYvl+AMMslksAd9ps6x0A71gsXwjghDo3loiIiIgohThjJhERERFRijEIJyIiIvIImfSaceQVDMKJiIiIPIY54fUfg3AiIiIiohRjEE5ERETkERLMRzlaMAgnIiIiIkoxBuFERERERCnGIJyIiIjIYwQ4MrO+YxBORERE5BEsUXj0YBBORERE5BHpjMFveX8hrnpjThpbcHRJ2rT1RERERFQ76agTPnnN3tS/6FGMPeFEREREHiGZj3LUYBBORERERJRiDMKJiIiIPIL94EcPBuFEREREHqFmo7BAYf3HIJyIiIiIKMUYhBMRERF5BhNSjhYMwomIiIg8RqSjRiGlFINwIiIiIo9ghcKjB4NwIiIiIo9IZAy+cudhvDF9YwK3SInEGTOJiIiIPCYRySgX//tnAMDvz+6egK1RorEnnIiIiMgj6ns6yi3vL8C7szanuxmewCCciIiIiFJi8poiPPHt6nQ3wxMYhBMRERF5hGSJwqMGg3AiIiIij9DSUVihsN5jEE5ERERElGIMwomIiIg8or4PzKQIBuFERERERCnGIJyIiIjIIzgw8+jBIJyIiIjII9R0FI7LrP8YhBMRERERpRiDcCIiIiKiFGMQTkREROQxQjAhpb5jEE5ERETkESxRePRgEE5ERETkEayOcvRIehAuhPALIZYIIb5Tfu8qhJgnhCgUQnwqhMhRlucqvxcqjxfotvGgsnydEOIC3fIRyrJCIcSoZL8XIiIiolRgMkr9l4qe8HsArNH9/ncAL0gpjwVwEMDNyvKbARxUlr+grAchRG8AVwPoA2AEgP8ogb0fwKsARgLoDeA3yrpEREREGYnpKEePpAbhQoiOAC4C8JbyuwAwFMAXyirvA7hM+flS5Xcojw9T1r8UwBgpZZWUcjOAQgADlH+FUspNUspqAGOUdYmIiIiIPC3ZPeEvAngAQEj5vRWAQ1LKgPL7DgAdlJ87ANgOAMrjh5X1teWm59gtJyIiIspI7Ag/eiQtCBdCXAygSEq5KFmvEUdbbhNCLBRCLCwuLk53c4iIiIgsSSUfJZEVCiVzXDwpmT3hZwC4RAixBeFUkaEAXgLQXAiRpazTEcBO5eedADoBgPJ4MwD79ctNz7FbHkVK+aaUsr+Usn9+fn7d3xkRERERUR0kLQiXUj4opewopSxAeGDlVCnlNQCmAbhCWe0GAN8oP49Tfofy+FQZvnQbB+BqpXpKVwA9AMwHsABAD6XaSo7yGuOS9X6IiIiIki0ZfdbsCPemrNirJNxfAIwRQjwNYAmAt5XlbwP4UAhRCOAAwkE1pJSrhBCfAVgNIADgTillEACEEHcBmAjAD+AdKeWqlL4TIiIiIqJaSEkQLqX8CcBPys+bEK5sYl6nEsCVNs9/BsAzFssnAJiQwKYSERERpQ17rY8enDGTiIiIyGNEAqfrYVzvTQzCiYiIiDyDIfPRgkE4ERERkUckIx2FJQq9iUE4ERERkccksk44eRODcCIiIiKPYJ/10YNBOBEREVE9xsDemxiEExEREXkE07ePHgzCiYiIiDwiGYMovRLYc4CoEYNwIiIiIko6xuBGDMKJiIiIPKI+x6n1+b3VBoNwIiIionpMeiT8ZTqKEYNwIiIiIo+oz3FqPX5rtcIgnIiIiMgj1F5rkcDZeno+8kPCtlUX9fkCozYYhBMRERHVc6FQ+iNgr6TFeAWDcCIiIiKvSFKcGvRAN7QHmuApDMKJiIiIPCZxyShhgSAjYK9hEE5ERETkEckKlQOhUJK27B57wo0YhBMRERF5RLIC1aAHcsLJiEE4ERERkccksDgKACAQRxCerHreHJhpxCCciIiIyCOSFajGkxOerN54pqMYMQgnIiIiqufiyQlPVqzMGNyIQTgRERGRR3ghJzxp6SjsCjdgEE5ERETkEWqYmuic8Jp40lES+9JJ326mYhBOREREVM/F0xMeSlpPeFI2m7EYhBMRERF5RLJSNmqCceSEsys8JRiEExEREVHSsUShEYNwIiIiIo9IWid0HBtmicLUYBBORERE5BVKoCqQ4JGZcTUhWZP1kB6DcCIiIqJ6Lp7AOnk94XXf8KKtB7F+b2kCWpN+jkG4EMIvhPgoVY0hIiIiOpolqxf6kldm4c6PFrtsg3dd/tpsnP/CjHQ3IyEcg3ApZRBAFyFEToraQ0RERHTUS3SdcAAYv2K3q/WSNllPUraaubJcrLMJwCwhxDgAR9SFUsrnk9YqIiIioqNQXePfmmAIAkCWv/YZx14YHHo0cPMX2gjgO2XdJrp/RERERJRAaqC6fMdhlFTWxP38no98jyH/mJaQNiQaSxQaxewJl1I+AQBCiIZSyvLkN4mIiIiIbv9wET6+dVBczwlJYNfhyjq9brLSURiDG8XsCRdCDBZCrAawVvm9rxDiP0lvGREREdFRRh+nrt5dkp42MAZPCTfpKC8CuADAfgCQUi4DMCSJbSIiIiI66vmSMTrTBeaEp4arrH0p5XbTomCs5wgh8oQQ84UQy4QQq4QQalpLVyHEPCFEoRDiU7XyihAiV/m9UHm8QLetB5Xl64QQF+iWj1CWFQohRrl5L0RERERepU8FSVsQnrTqKIzC9dwE4duFEKcDkEKIbCHE/QDWuHheFYChUsq+AE4GMEIIMQjA3wG8IKU8FsBBADcr698M4KCy/AVlPQghegO4GkAfACMA/EepX+4H8CqAkQB6A/iNsi4RERFRxvOladJM9oSnhpsg/HYAdwLoAGAnwgH1nbGeJMPKlF+zlX8SwFAAXyjL3wdwmfLzpcrvUB4fJoQQyvIxUsoqKeVmAIUABij/CqWUm6SU1QDGKOsSERERZSR9nJq+nvAkbTc5m81YbuqECynlNbXZuNJbvQjAsQj3Wm8EcEhKGVBW2YFwcA/l/+0AIKUMCCEOA2ilLJ+r26z+OdtNywfWpp1EREREXqAPgP1p6gpPVtpI0qquZCg3PeGzhBA/CiFuFkI0j2fjUsqglPJkAB0R7rnuFX8T604IcZsQYqEQYmFxcXE6mkBEREQUF7UjfNehCuwtqVvZwbgkqyecMbhBzCBcSnkcgEcQzsleLIT4TghxbTwvIqU8BGAagMEAmgsh1B74jginuED5vxMAKI83Q7gii7bc9By75Vav/6aUsr+Usn9+fn48TSciIiJKoeiBmaePnoqBf5uShhZQMrmtjjJfSnkfwr3ZBxDJ3bYlhMhXe86FEA0AnIfwgM5pAK5QVrsBwDfKz+OU36E8PlWG71uMA3C1Uj2lK4AeAOYDWACgh1JtJQfhwZvj3LwfIiIiIq9LWzoKo/CUiJkTLoRoCuCXCAe53QF8hXAwHkt7AO8reeE+AJ9JKb9TJv4ZI4R4GsASAG8r678N4EMhRCHCgf7VACClXCWE+AzAagABAHdKKYNK2+4CMBGAH8A7UspV7t42ERERkffoA+A0FUdBKFklChncG7gZmLkMwNcAnpRSznG7YSnlcgCnWCzfBIsgXkpZCeBKm209A+AZi+UTAExw2yYiIiIiL9PHqWkqjpK8EoVMdDFwE4R3k1JKIURjIURjXdlBIiIiIkqSejdZD2NwAzc54X2EEEsArAKwWgixSAhxQpLbRURERHTUSXaJwqpAzEnPWSc8RdwE4W8CuE9K2UVK2RnAn5RlRETkcfd/vgwFo8anuxlEVAsiCT3h1YFQwrfpFuuEG7kJwhtJKaepv0gpfwLQKGktIiKihPli0Y50N4GI4iANJQrT1Ab2hKeEm5zwTUKIRwF8qPx+LYBNyWsSERER0dGpfs+YmZTNZiw3PeG/A5APYKzyL19ZRkRERERJkox0FDeSFywzCteL2RMupTwI4O4UtIWIiIjoqKYPU+PtCHeTc+0mDE5aiULG4AZuJus5DsD9AAr060sphyavWURERERHN3+cPeEhF0Gum0A4aSUKk7LVzOUmJ/xzAK8DeAtA7Lo2RETkOaGQhC9do7yIyDV9ABxvnfCgqyg89ipuNlMb7Ak3chOEB6SUryW9JURElDQhKeFL2yTYRFQb8aaE66eb/3zh9pjr2GO0nApuBmZ+K4S4QwjRXgjRUv2X9JYREVHCBNkFRZRx4u0J1wfYf/5iueU6rkLwpJUo5HFIz01P+A3K/3/WLZMAuiW+OURElAyh9M3PQURx0AfAPjddpTpu0lHc9IRzYGZqOAbhQggfgFFSyk9T1B4iIkoCd7egichL4u4Jd3Gx7W5gZlwv6xoPQ0aO11hSyhCMPeBERJSBmI5ClBn0KRvx1gl38z13V8YwWdVReBzSc3OjY7IQ4n4hRCfmhBMRZaZQssodEFFCGWbMjHNgppt0lLTmhPMwZOAmJ/zXyv936pYxJ5yIKIO4Kl1GRJ5Sl4GZdVmHwXJquJkxs2sqGkJERMnDGJwoM+gD4HjTUeIJsN+auQmzCvfh3ZsGRK+TrHQUHocM3MyYeb3VcinlB4lvDhERJZLfJxAMSQ7MJMpA/iRWR3l6/BrbdViiMDXcpKOcpvs5D8AwAIsBMAgnIvI4nwhPdcx0FKLMoP+msjpK/eYmHeWP+t+FEM0BjElWg4iIKHHCt7PZE06UKeo0bX2C8r2TVx2F9OK80QEAOAIOyiQiygg+5RzOyXqIMk+809a7q46SvoGZbsojHk3c5ISP0/3qA9AbwGdJaxERESWMXzmLs044UWaoUzqKq+oowNxN+123IZF4FDJykxPeDpEJewIAtgG4K2ktIiKihFFP4kxHIco8viT0hH+7bBeen7TecR32WKeGmyA8S0o5Xb9ACDESwF+S0yQiIkoUoaWj8KRKlBF0X1VfnFG4m4vtrfvL42lCQjG2N7INwoUQfwBwB4BuQojluoeaAJiV7IYREVHdqSdxpqMQZQZ9znZyqqOkc7IeHof0nHrCPwbwPYBnAYzSLS+VUh5IaquIiCghtHQUDswkyjhxp6MkaMbMZAXL7Aswsg3CpZSHARwG8JvUNYeIiBJJq47Csx9RRtB/Vf1xRuHuqqPE14ZE4lHIqDYlComIKEOoPeGcrIco8yRz2nrn7UR+/nHVHvR7ahIqa4JxtaW2r300YRBORFSP+ViikCijGEsUxvfcxPWER9Z6avxq7D9SjaKSqvgaE2O7xCCciKheU0/iPPkRZR6BeAdmJiYnXL+GOp4k3omDYm2XGIQTEdVrQktHSXNDiMiVulwvu8o6czNtfdJmzEzOdjMVg3AionpMHdjFnHCizKAvUehmink9N2ln5m1+umAbbn5vgX0blG0mpiecxyE9BuFERPUY01GIvOeHlXtQMGo89pfVPc9az1U6iumu2F++XIEpa4uMC2X0j/HWLLfEw5ABg3AionqMAzOJvOfdWZsBAOv2lkY9pv+qxvu1dXPHK+6c8IT2hJMeg3AionpMPXEyHYXIO7L87ibRMn9rpZT4cO5WHK6osVzfXTpKbFYXAryOT7ykBeFCiE5CiGlCiNVCiFVCiHuU5S2FEJOEEBuU/1soy4UQ4mUhRKEQYrkQ4lTdtm5Q1t8ghLhBt7yfEGKF8pyXRbwFNYmI6jm1J5wnUCLvUL+XAYso3OmrunjbQTz69Uo89NUKy8fdpKO4ORYY89KVbSfgIMLjkFEye8IDAP4kpewNYBCAO4UQvQGMAjBFStkDwBTldwAYCaCH8u82AK8B4aAdwGMABgIYAOAxNXBX1rlV97wRSXw/REQZh5P1EHmPOmDaMrDVLTM/XFkTDtoPHqm23K6bnnCrwN+hCQntCefATKOkBeFSyt1SysXKz6UA1gDoAOBSAO8rq70P4DLl50sBfCDD5gJoLoRoD+ACAJOklAeklAcBTAIwQnmsqZRyrgyPOPpAty0iIgLgU072t3ywMM0tISKV33Xp0PiCVvVa22mSn+pA7CDceHEQ/jkhQThjcIOU5IQLIQoAnAJgHoC2UsrdykN7ALRVfu4AYLvuaTuUZU7Ld1gsJyIiRbwz7hFR8vkcSofGm7Otp6ajOFUyCcQ5q6b6WglJR6nzFuqXpAfhQojGAL4EcK+UskT/mNKDnfS/iRDiNiHEQiHEwuLi4mS/HBGRZySkrBgRJZTaEx4rsK1tdRSfw9W3m55wfWSmtjERwRpLpRolNQgXQmQjHIB/JKUcqyzeq6SSQPlfLU65E0An3dM7Ksuclne0WB5FSvmmlLK/lLJ/fn5+3d4UEVEGYU84kfc4TaLlpkSh3bW1mhPu9L2vqA5aLtcHyEkbmFnnLdQvyayOIgC8DWCNlPJ53UPjAKgVTm4A8I1u+fVKlZRBAA4raSsTAZwvhGihDMg8H8BE5bESIcQg5bWu122LiIjg3CNGROmhBtFWga1dMOyGm3SU8pqA5XK74D8yMDMhIzNJJyuJ2z4DwHUAVgghlirLHgIwGsBnQoibAWwFcJXy2AQAFwIoBFAO4CYAkFIeEEI8BUCdU/VJKeUB5ec7ALwHoAGA75V/RESkYDoKkfdkOVVHccE2J1wbmOkQhFdZ94SHbKqyqMsTUWCJ1VGMkhaESyl/BmD3KRhmsb4EcKfNtt4B8I7F8oUATqhDM4lcW7enFO2b56FpXna6m0LkGjvCibxHvUMVCNoPzGyQ7Y8KtmN9nd3Mblluk46iD7INL5vIEoWMwQ04YyaRSxe8OAO//e/cdDeDKC7sCSfyHjcDM4WwmDEzxnbVlBGnb31FjZue8PRP1iOlrPcDORmEE8Vh5c6S2CsReQiDcCLviQzMjH5MjTudvrl2X+u6hKwhi8B7874jKKsKRD0OAN8s3YkNe0vjeo142nfOv37CSY//GNf2M00yc8KJiCjNfOxqIfIc4dATri7xCWHbcxyzTngt8tAM6SjKz5NW77F9zXvGLAUAbBl9kevXiKdne+v+ctfrZioenomI6jH2hBN5j6uvpYgeyBg7Jzz8/6HymrjbZJWOou+pdxM/7z5cgQ/mbIn7tY9W7AknIqrHBINwooziJq/b9rl1eV19wK38rw/M3eSE3/TuAqzdU4oRfdqhTdO8hLavPmJPOBFRPcbqKETe5RSUCouRmW4HZtaGVYlCqwGaTvaVVYV/sMtZ121k9S6OsWIQTkRUC9sPlGP489NRVFqZ7qY48rMnnMhztG+lQ9Dss6iOEktdKpgYB2ZGp6O42bY6A6j9cSeyjQVbDtisUzeZVFWFQTgRUS28O2sLCovKMG7prnQ3xRHTUYi8x+lrqVVHsVgp1re5LrGn1cBMu7KFdgIxZuzUb8KfpNt0v3jlZ3R9cEJStp1oDMKJiGohU2JbpqMQZSaB+NNL6jKrpVXqibRIUXF8faUBdqvql2cl6eCUSaWEGYQTuZApt7bIWyau2oPbPliY1jawOgpRZlFTQYQQKU1HCVr0euuDemNPufXrqD3hdo/H6gl/c8ZGnP/CdLdNznisjkLkAmNwqo3ff7go3U1I2i1fIqo754GZ8Z976jYwM3qZPjC3GrgZtb6uJ3xvSSU+nLMV9513nFa3XF9yMcsffWz624S1tWh55mJPOJELjMEpYzEGJ/Ic4fDFVIPh2lw/1yknPBQdZNuVKLTrcY/0hAP3jlmKV6YVYumOQ5bt83MmMQbhRER1wbskRJRIAaUkSbbfV4t0lNq/rv5YpvZYvzF9k36h69eRkKgKBMPr6oN73TrZvEvHIJzIDeaEkxlPH0RUV1anlupgeGGO31eLgZmJKVEYClk9HsfryEh1F/2a+vfjYxDOIJzIjaMpBK8OhDDqy+XYc9jb9a/JpaPpw0uUIdTx0lZBdiAYClcOUdaZunZv1Drm6ewjy2vPWCfc+fFYQbhEpKPCblXOYcAgnMiVo6kj/Kd1RRizYDse+XpluptCRFQvOYWfgZBEtj8cnoWkxO/ec19hySqo79Kqoavnxqp+Im3WtW6H84UGwEHjAINwIqKkS2c6k77HLBAM4f7Pl6GwqDRt7SEiZ9WBELL84aGblTUWeSGwH9hp1UPtNkVFf5w6XFHjuJ3YPeFSa6MxHSXys1V1lKMNg3AiF+xu/WWifWVVqKgORi3/YeUe7C2prEfv1Du8cCclL9uHtXtK8cWiHbhnzNJ0N4eIYJ32EQiFkO33QQiByproY7Xj9iw2aJXfbUVfjvDp8Wsstq1LV4mxzZAuH8VqwKd5eTLM3FCc3BdIAAbhRC7oDxYLthxATdDlUc2D+j89GVe8PtuwLBSSuP1/i3DVG3PS1KrM5eYCLZ0xuPrZzc3ya71XTMUkLwsEQ3hm/GrsL6tKd1OSxmpKelUgKJHlEygsKsPsjfst19Efd+4ZswSnPzsFgE2tb5clU0Ih57KI+vNgzJ5wKSM54TaBd10Gkbpx3dvzk7r9RGAQThSnK1+fg39OXJfuZtTJql3GaX3VQ+H2A+XaMgZqzuLZP16orhOSUjsBchZN8rJp64rx35mb8ddvVqW7KWlRHQxpOeFRLL663yzdhV3KQHrrXG6XQbiUaNkoBwBwRb+OFo8D09cXo+uD43HIIl3F8Jq6nPC//7AOJz4+UVseaRcxCCdywXxcW7enfuXUqgduHhSTwws94ZCRnieG4ORl6vGoKpC5dxzdsro+DwQlsv0Cvds3tXhCjO1ZLNPfuM12yMM29FJb9J6HpMQrUzdASmC1qSPHipoTvmz7IZRWBqLbxxMOg3Cio9W4ZbsYfKdIsm+7um2Del51uhVOlG7qnRov3EFKNruc8Cy/Dyd1bGb7PNuBmRbBs34/ZjnMUqk/TgUst2O9rhV9T7hdW5x66I+Gvz3AIJzIFfPBoj7EMHd/sgRfL90JwBsDB+uzdO5f9bMbkpETGyuDkZepcaIXLl6TxekcUhOU2sDMeFmlf4cMQbj9NvXrlVcHDemJQPj4sWDLwah1rUhI6yDcsD2H59ffP71BVrobQJQJ6usB4cCRcF5fKkes1xfabHAZsr9CMvJXZk44eZnay1uXKdgzWU0whGy/cB4kadOLbBUc65fkZPkAm/Gu4Qv18M+T1+zF5DV7ox5XxRrsKaVNb72hN93h+Y5brz8YhBO5YD4gZGoIY3fgtAokM/U9pkpk5H9sae0JV15bInKrmjE4eZk2yUt6m5EUUkpc/tpsxxmJ1eooVpPZLNl+KO7X1G8lL9vv2DYnFbpyibEGzUrYpKMYOnzsX68+3wXRYxBOdBQJuC0Yi/p5AkwXL9SZl8wJpwxRn3PCgyGJxdsOab9bvceaYDgn3OqOVXWMwaqxesJzs+yzkGP1bt//+TLt57KqgOO6W/YdQZXFRENuq6PUwz+9JeaEE7lQX04G5oOs1pubQW8vFJKYtrYoo/4m6c0JD2NOOGUKNfisj72hQdN7snqLNcEQcvw+y55ktXc8nhkz9XIcgvCQjA6Mc7J8OPu4fMdtWrnpvQWYv+VA1HK3OeF27yOTjvtuMAgnciEqHSVDexK37jcOtInc9o0+sHn1HX40fxtuem+BNqg0E3jhtMGccMoU6kViHDfuMoa5I8Tq2BsISWT5heX3VA3C7e6uxUotzI0zHSUUkpZpMbVlfIn4j4xOMXgwJPHo1ysNywpGjY971tFUYhBO5EJ9ufge+dJMy+Va3nAGvM8dB8MXErsdcirN1u8txe7DFUlpj5t9ls7eG/3fljNmUrqMX74b36/Y7W5lNQjPhANSnKKCcMuecIksn8/yjlWsY4lVRol+UV6MnnCzoJRJu2h3yn6pzd9+5c7D+HDu1qjle0vcnytSjTnhRG7Uv3MBALvBhfXvzZ7/wgwAwJbRFyVuo/HMmJm4V60TNQBgTzil2p0fLwbg7jvoy7DKQ/Ew9+5b1gkPhpCTZd0TXhOMVZXE+XGnnvDwrLrRFwl2k3fWhttKXHaPOb07q9rmQOx9lk7sCSciywN3rDht+Y5DuOzVWSm/1WeXC+llXgkmglp1lMzbh3T0iHQORL44q3YdxtxN+9PToAQyD4636vGtCYaQ5bOuE14ddM7RiZmO4tgTbn2gSlY6itOA9RvfnR/3tu3a/6fPl+FweU3c20sFBuFELkRN1pOmdiSaVuva4rFYgeNj41Zh6fZDWLXrcOIbVt+kNQiPvLgWhKerKUQu+HzRdcIvevlnXP3m3DS1KHHcDcxUc8KjHwvECMJjpXE4BeF2T03UnTMppeuBmeqkQFbbsBOw6fFetv0QXpi83k0TU45BOJELXunJTBb9+/tm6S5Xz8nEyirp4oUShYA+HSV9bdhUXGY5tTaRSv181rdKGIC7waaBULg6Sm3SUWJ9tXKzYqSjWCx3mmXT6TEzKWE4YSQ65z8TxxAwCCdyIfO+2u4Ii6Tw71fuMT5m+1z7XvRUyKTjbTpjTv1+Unvh0pWOsn5vKYY+Nx2vTitMy+tTpqi/M2aa01Gs64QrPeEWAW6N0hM+d9MBfDJ/W9TjlhVOdItys+OvE27VDlWWP/JYrItribqfL2qTEw5494KOQThRLdSXlFqr3Mu4n+vNY5ulwxWJzwt0s++8cgI4okywka6e8F2HwhVqFmy1vtVMFBb+vnjle+OkKhCMOXGNnrkn3CpuVHPCrb6n+sl6Hhy7Iupxqz2m7yHOcRhlaRfD+h1OeNm+yPZqYnTzhwd+Rn6XEigqqcQT365CwajxKKms2/E5VqqOFyUtCBdCvCOEKBJCrNQtaymEmCSE2KD830JZLoQQLwshCoUQy4UQp+qec4Oy/gYhxA265f2EECuU57wsONKoXtlYXIbp64vT3QxNJpwM6qI2b09k4C3jI3GcLGOJZ4BoOveQ/rUfUWroJuJwuetQRa3/9pn0maHU08pqprcZrvzy1dk44bGJrteP7gm3WCcokW1TJ7ymFjnh+h5qp/xuKaVlb7bTwMxsXY65XU52ZPvG7/7ff1iLAX+bgndnbQEQDshjcTp0OM0m6tXPUjJ7wt8DMMK0bBSAKVLKHgCmKL8DwEgAPZR/twF4DQgH7QAeAzAQwAAAj6mBu7LOrbrnmV+LMtiw56bjhnfiHx2dLBa1Q9LQiuSJdYB6ftJ6/PGTJYZlahCa6oNbJl5ueyXmVPNJ69oTvnzHIZw+eirGLNge1/PYV0JuqF8XtWSelwd/r95dEtf65iDZ6k5aTTCEbL91T3htcsL1g0FbNMx2fK5VSopjOorusZhBuOndxjPXQ6SN9q9R5RSEe+QYbJa0IFxKOQOAec7SSwG8r/z8PoDLdMs/kGFzATQXQrQHcAGASVLKA1LKgwAmARihPNZUSjlXhi+rPtBtiyjhvPoFrjOtHq/zG3x5ygZ8u8w0YFPrCU9GwxLHLs8xldI5MNPqb7t1fzmW7zhUq+1d89Zc/EapUjF7Y3wl4+xSmNbtKcXswn21ag/VP+rnIxQC3pu9BRe9/HN6G5RA5o5s8+FJSqnMmGldonB8jAmPYuWEN8jxY8voi9C3YzOL9cKv3b9LC8Nyx3QUXXqLuZc/um21qw3udh3nnvD0nwespDonvK2UUv0E7QHQVvm5AwB9l8oOZZnT8h0Wy4mSwqtf4LqynqwnbOKqvY45epnSpxnr9m1KeOzjs3ZPKS55ZVatnjurcD+OVIdrw1cH4qsRr6UwmXbIBS/OwG/fmler9jjp8fAE3P7hooRvN5NUBYI4cKQ63c2IixpIhqTEql3x9TR7XVSgaooq1cGF2T7rdJRYrIJUqxQTq76JkJQIhiQGdG1pWO6YjqIbmOk0MFJtm9MaU9cW2T4WDEkcLq8x9ISbLziq4jweeUHaBmYqPdgpOTUJIW4TQiwUQiwsLvZOnnEmOHikGk9/t9obgYyH1Je76ur7sLvFt3TboZjbMAdUH87diu4PTfBMGTr9iSEZfzdXvTeJf1nXkvnaTj1PVrQUphTtkJqgxA+r9qTmxTzq9x8uwqlPTUp3M+Kifjy8fpetNmLNmKmmdGRnWaejOFm/t9Q6JzzGsg7NG4TbIsPHyyyfwI2nF2iPOwXh+lSVWHGCRPSMnHrPfr/W9rEnvl2Fvk/+iPLqSKBtPsUwHSW2vUoqCZT/1cuenQA66dbrqCxzWt7RYrklKeWbUsr+Usr++fn5dX4TqXbd2/PwwqT0FJr/+w9r8dbPmzF+ufMtsHrPo1/ghLF5f80a2OcP+iLdmgZPfbsawZCMObNbbcUbR1fpZvRM5Gyb8QT0Xj0B1FW8f+P6cvGaSX5al1kdT/vKqrBa6f32Qt3n5TsOYeXOxOWkx5qsR/1OZdWiJ/z8F2ZoJWb1rHu9Iz93bBEOwtUOC7/Ph0a5kXrijjNmSmDD3lIMfnYK9sTI8a5tv4yUEl8vCYd4H83bqtueuSfc/njkkT6hKKkOwscBUCuc3ADgG93y65UqKYMAHFbSViYCOF8I0UIZkHk+gInKYyVCiEFKVZTrdduqd2Zu2IeXpmxIy2urH/JMvM2TSB79/iaM3fszH3z1PR2RXnTTk0zH6+LSKnwwZ0ud2lcXlXH21iZDenPC7R+LddKMpSZQ2+oodXpZqsfOf2EGnvxuNQBvHHcveWUWLv534nLSgzGmrVfvIGb5hKuL1ngrDQmLcUDqcV69s6Wv/Q04V1QJSYk3ZmzC7sOV+HH13oS2NfIakWPGi5M36Ja7D8K9KpklCj8BMAdATyHEDiHEzQBGAzhPCLEBwHDldwCYAGATgEIA/wVwBwBIKQ8AeArAAuXfk8oyKOu8pTxnI4Dvk/VejmbqoItYI7Lru/oaNMRKDzAPaqyoiX0xph6u1QPknR8vxl+/WYWNxWW1bqcb+8qqLAcbVuhuX6YrGPbq5+fat+PLw15tys+tbU94fR1jQXWnz19PZk/4puIyFBaVJm37dsxfGfM7VN+zzyece6AVE+NMt1IDYf2xXX0dtZPF7xOGY5a5tPhJukGdEpHSr3lZziFlZU2oVsfCQChk+VkwL3LuLPTmMScrWRuWUv7G5qFhFutKAHfabOcdAO9YLF8I4IS6tJFiU4PwTCyCn0yZelddCOOBK1ZQZB5oU1EdRNO8bKzadVirjGF+rrpN9SB/qDx8Uk32uIIRL87EvrIqbBl9kWF5ZY19DmFdxPMZSMfhv//Tk9GxRQM0dUgp2htHT/jEVXvwe9Mgx1TlhG8qLsOcTftxzcAu8T2RMlsSvzhDn5sOAFHHi2Qzd2xE9YQrvwohXOWEF5VWuXrdIcflY8b6Yu2Yrn9dtXe8RpcKo2+muTqK/uIgJKU2WVFuth9OTntmMh66sJer9upVVoe0weB65n0Z7/HICzhjJjlSa4DGGvVc39kFqRXVQRSMGo9vltoOScgIdkGR+QShDorRlwwzP1eYppxWb2VW1YSSepDcV2Z9MjIE4Wn6HKdjcpp9ZVVYuv2Q4zqxZrjT21R8JGpZbfP+490bF748Ew9/tTL2ilSveCEnPNHMgeO4pbsMxyj1WOETQNMGsftJ3R7TTuoQ7r1Wj8FN8iIX52pMXa3rCTcwB+G63ytrQti874jrttTmT3r7/6wrHMWTjuLVjxKDcHKUpfSEJ2uQXaaw+wLvPhyehlufp+Zl0QGzstxmffPkCxUWvRFRKeFqrrjpgHzpq7Nw+uip7hrqgtvAtrIm8tlNxoH4x9V7Y7YlnScAp7bFk2aW7Y/ulou7J7yWt5DUvyFn2jy61Me+H/PAzN2HKzFaVxVE33nRtkmei+25e90cJVVE/c6+fm0/dM9vpL0WAKzaGU43y/IJQ8dTXrYxVNQH6cWlVdhxMHwerHQxdqw2f9I5m6znI4iqjlLDIJzqGfXEG2smrPrONtBUbx2mtDWJZxfc3PfZUsPvFTXR076bn6vui6DWoxPZO3a91fGYvMZ58I+ZPo89kbnI6ttatv0QxpknMgLwf58ujbyuR78+8UxklGVxb7zWKUa1rpJQu+dRZl7A1MexA+aBmQBQVBpJCwvpesLbNM2NuT23PeFaEK58Z9s1y8PNZ3ZTXiv83VYnAvL7fIbvaJZPYN5DkUxi88BNVUV17ONBbT6Gvdo1sdmWKR3F4Xjk1c8Sg3BylOVjTjhgfQIrrazB6O/XhH/JgCjc6j1oOeG2Pf3hk4MagJVb9YSbe9eFmo6iDjCqTWvtrd8b3wDPROWET169FwWjxmPHwfKox0oroy9OvloSSVHy6glA9cn8bdi6PzrdRM9vHp2F+HvC1ZN9bfeH19MTlm4/hI/nbUt3Myx5fNdZCoUy4tAaF6tT6YQVe7S7jOpnXAiBNk3d9IRH/2GtBnTm+I094Xrm1cM94RECxkGifpuD+juzNsdsb22++3bfe/V4vvNQBXYcLDeUo80UDMLJUXaWUrroKO8JNxMQeHHyBkxeEy51X5uZzVLN6jjmtm52njLgxiodxXyA1KqjhOJ7jWQxBuG1/xx/reT9L9p6MOoxp8GPgLcDoEAwhAfHrsDlr812XM+qJ7y26Si13R9eT0+47NVZeOirFeluhiWvX8BYycTe+1js7j6ps0Wqb9knBJrkusgJt9hHvds3jVqWq6SUWOVNm89fudk+w74Xwvj9tzoWuFWbP6ldrrfaOXjG6Kk48+/TnHvCPfpRYhBOjrLZEw4g+gucl+0zlEPyfgjunAEQ6wCl5gRalSiMOqmo1VG0Hh23LUys8uoANhaXWQ56qo3GygnxSFX0PmiU41wVIJ3Hf6teej31z7evzHlqc6veNaeT3nuzNuPRr60HU9Z2fyQrkFyw5YDhc1IfeTQGceT1iy63Bj87BX/5YjkA+yBcTe3Sp6MIFwdPq1RRn0NPuFUZP/N3u1PLhoZzQpapXGJdgnDVS1ef7Hpdu1zvksoaw+9O6XVe/SgxCCdHau7X0V4dxax5wxzLUn9eZhmAuqzbnJsVDjKt0lHse8Kl4fdEixWP/f7DRRj23HRDm+sSwzVSgvCyqpqox2LlVieqR69g1Hj856dCx3X2lVXhF7rJRWJVSHEb2FoOzHQIwh//djU+nBue3W7HwXIUjBqP+ZvD0zzUdn8kIwbfsu8Irnx9Dh77ZlXiN+4hye4JP1xRg/0JGPOhl4m991Z2H67Epwu3A7BOHwEi3yVzValYrO5GLbP4zpsHZuqZg/b8xrmGM0KW32cIwhvE6HRwoqbzjTyhPTq1bODqOVWBoOU59mC58VisvyC58MR2hse8+lFiEE6OsrTJepLTE97/6Ul4Vs2r9jDzFzg322c4SGVEOorFMq06SowDlHor0yodxfzRMOeEu+nNSYaZG/YBMF441OVasoGSkqNW6tCn2cQMwi2WhUIyrqBF/Q7+44d1AIArXpuN4c9Pj1rvs4XbsSLGNNt9OzWPtMPl2SnLIg/U7YltdmG4usHnSiCiPk1KiecnrXe3EUS3NRiSdZ7N93BF+ES+Zk9JjDUzW7KDkP5PT0K/pycndJup7vsJhSS+WbozrgHLtXkNK2pwHIrzDqLbOzhqR4o+CFc7X8wd203zsg2fl2y/sSe8YR2C8E/mh48BQkTutMdSWRNCXlb0a+ondgKMFzgNspM2DU5CMQgnR1qd8CTlhO8rq8Yb0zfZPu61nMBnfhmeH0pK86Q3GRCEW3WEawPlnKl1Ya1OTlE94abJetK9a9TZ3IC69az5HWrmx7pTZH7ZV6cV4p5Pl6Lf05NRVOJuwhw1FUjtkV649SAKi6IHqZZbpMvoNcj24/TurbTf3QYcuTFmw3Oili5Te+PU/bF1fzlenhIp72n1fdcvM//9rn9nHno+8kPM17e6eDzaJPtQGk+5yzdnbETBqPEu1kzt8f/Thdtxz5il+GDOlqS9ht2xQr3IjtQJD3/Pv7h9sOP23E7Vrn5/rdY3T8bTOC/LcHdUQBguwhvm1D3AFYhMBhhLVSCIFg2jx90cKq829Prrj2XmC4UTOkTnyXsBg3ByJdmzHdrxShaMekDKy/KjQbbftiyfl1mlnKjvw+li5/kf12GPEihanUBs01Gk8fdUkaaepCPVAd1jtd+uekFqVWIsEHPSm8gLH66owT8nrsO3SllDtzPeVSqBZE6ME5f+/eqdVtACQHT+p9vvWG13XU0wpOV0akG48ph5v1m1xXAnw7SbZxVa1w82O++F6DsGZh673k84L6V2/G1CuC52rPJ6qT7+q3emElFK1Y7de16oDPg2p6P0L2jpuL1YPeGPXtwbX91xumU6ypnHtgYAXNGvo+E55mNEUErDsvbNYldtiUUIgQPlzuNQVCEJtG8enbpy4EgNLn11VqSd+iA81xiEDz++bS1bmlwMwsmRetyuScLR0E0vt1dOHGozhAjfugvvjkjbEl2GLxmsdqU0/W/l5amF2uA+qwDU3JMaVaIwzq7w5TsOobQyOu/ayrS1RXjtp42GZebgv6wqMdVR1NQsq7tCse4U6V+2tnd3tJ5wU4+0eXt2PeGDu4dPuD4B/HZAZwBAt9aNDEFBRXVQuzgwq227y6uDWqBgvoAwH1as/j5lCbiToU4mYiXdd2pSxRtHUqNYf8903Ql1+7JfLtoR97btcsLHL9+N+ZsPGAZmao/dfSaeuKQPPrplYNTzyquDjtPb33xmV5zSuUVUnXAA6NKqEbaMvgindY0O9NUAHYjufMlvErt+uRv6u5SxtLMo13jIFMTrP0+NTL31Xv2eZ0DoQOmkfqiTUR3Fze1LzwThyv9CGbEelY6SEX3hFpT3YLWbrQ56Vh8Dm+IotUpHqQ6EcMkrs3DL+wtdrX/Tewvw9x/WGpZFB6WJ6QlX00C+WLQDn8zfZpjyPZ6c8Nq2Qe0RNt/CNVessesJz/ZFUo86tWyIs3q0RtMG2Ybv2BPfrsIfP1mCxdsORj2/ttfhFdVB7Ra4GgioO8G834IhiW37y/HwVyu0Y06iSkymktsJVFLJi/su1m4KhmTU8SMYkrjs1VmYuja+SbvciDet8E+fL4v7NZxS13YeKtcdNyNt6XNMM9xwegHamXqg+3ZshrKqANo3iz3A0blOeOS11LKIw45vi8tPDfeQB00H/laNcl1XSGmSZ526ImA90N+OVR76QVMQru8MMa/v1XFbDMLJkfqRjiffzy2nygra63vkvKGlOECgcW5W1Jffzfd79sZ92LLPeUKUZLI6CUuHvvA9FrnKVj3h5oAjMpto9MnEbRutgkAzu4+G+RxnHJhZ95zw/Ueq8eDYFWiaF8lRjJUTrn/d2rZg/d5SAMAxphPxIVOFALsTm9qTrzYlL9uPypqgoWdO7TG26k13s+9+WleE696eZ7gQKq8OaIH04m2Hwm1QHjMH4SEpcd9nS/HRvG1YtiO8rj5oSGZsm8gJlex6O1NlU3EZ7vt0qSGNUHqwymysz1RJZQCfLTT2Nn+3fBeWbj+Ee8csTWLLkifWBVqkTnj0Y/rAskebxmiUm4WyqoBWPtVJW6VT5TSL9Bb9a3Vq2VD7WQ2gzaf/lo1yUPi3C3H72d1jvu4xNhcI8cbEViVSzdVR9J8ncwUXBuGUmdSe8Jg5r/FzM9HHXR8vjntCkGQSAujZrgnW7imNe2Dmb/87D+f866fkNS4Gq/Pd9yv3QErp+mLHKtiMDjiUdBTlzxarhrZhWyE1R931U6KYg3999Yy6hEZRE1ro0kJi9YTrvz61vRCYVRiu9tKrnXGAkfmC0O4Wr9qTr75+AyUIN6TKwP7uhd1bVIOKglHjceO7CzBzwz5D73y5rie82vS/eVeEZKRcmnrhr79YT0Z6gtNdrMqaIGZv3Bf3Nv/y5XLsdTngNhn+77NlGLtkp6FKjhdnba3Nd+EeJfguqQzgPRczNNZWIBjCS5M3xF4xBvNn1umCXcrIPrEKOpvoLvz//dtT0Cg3C0eqAq7+tu2a5eGn+8/Bgxf2inpMf/66d3gP7We7cTAtG+UAsC5batZPGYvi9JpuCBH9euZ8eP2+Nd8x9GgMziCcnKmf6WRUR3FTWmzymiKtRyyd9O++V/smKCwqNaQjePT7bWD1F/xpXTHGLt7p+vRsFWw+OHYFpq0r0n5XD3ZT1xbhcEUNWigHbFfbV05AISkhpdTKx1mxO3+bl+uDOPNJf8z8bViz27o0XUV1EAd1JbCcAoZYA5d3HYrkJNc2VWHVrnA7zSfcw6beIKsJlYDICTXSE+7Dlv3lhkFokVlOo9kFwNXBUNRj+gmNKmqCUSfLtXtKMWXNXsuSg+qJVt2nqeoJt/LEt6vw2//OwwblLoTZ+OW7tRlU9Z+BsYt34q/fWE9UlApWf79E77tAMGQ5e2w86tqmx79dXbcN2JAAxq/YjRcmuy+faf4O/LSuCAWjxmP9XmMFI6fvfzgID/9s1XOr79AQCM+oWVYVcL0fC1o3ilmR5Pw+kfrafi0IN67TolH4YsDqmLj52QsNvx+b3zhqndoGxMebZgI1H1f01aLM1ZwYhFNGUg8sblJH4uW2h9sL+ZX6Y03Ptk1QEwznrqpS/QUvqwrgk/nb4uoZtFt3/5GqOvWEA8BnC7ZrP6u74oXJ63H3J0tcTb2sUv/WIQmMWbAdfZ/4Edv2l2POxv0oGDUe2w9E9vmmfdHl+cLPNbbRUBfX9NiosSsw8qWZltu5+N8zccpTk7Tf1YlmItuK/FxSUYMHx66wvWhYrQv0a5uqoJbZU/8Gao6n+ZasXU+4mo6i3SlQ/lI3vDNfW0cL8C17wq3bXVkTjM5L17VB3xOu98b0TVH7IhSSWik0NajVp8LVJZ0oFJL4YtGOuO6sqQGUeR+r7vx4MS5/bTaA6DQgr00ynOi7CM9NWo/LX5uNVbuMNen1ryOlxPcrdttepCazHnddxXsH1rx7xykDnOdvNlbwcfr+SzjXCTf3HjfKzcKOgxWWpUoT4eKTjgEADO3VxrBcrTmufjdHjYz0rpvbqM4xoefmo9iqUQ46mCqivHZtP8PvTuUZzfMaeHXcFoNwcqR+V+o6MLOsKoDff7gQRaWRW7RuD3LeOExHUhzUmRP1gUeq882eGLcKD45dgbmbDsReWWG3H7N8Pte3qs0nXG3buqfnZUd6a7bpgmY39EG+WqXjlWkb8Jv/zgUQnl5c9c1Smyoept9r25O6sTicv7+3pBLBkMT3K/eYXieysfdmb8En87fhlanWt6/1ve1WedBuqJ839UKlaYPw5/DOjxcb1rMbv6H2aplPXPrp6rUqQBYnLLuMtKpAKOriQz84tEKXE64XCIUs90W2NkGY0gEQsL+TEWl37H34zbKduP/zZfjvTPt5CczU+slu/kbR79EbRy5VouPdlUqqi/7zA0S+w2/N3IT//LQRf/hoMd61SRsx/93M1S7SyRxMxjpfmXevevfY/H10O7uu3Tnlyz+cjrN6tEbHFg20cxEAnKybgOu7P57p+BpundixGbaMvgg92zWxfFzdJ3a966ufvECbkOesHq2jHn/jun545KLjLZ+76NHzMGvUUPzhHDXvXBiC8hy/z7E8o7lJdZlgKJkYhJMjLR2ljkfwsYt3YOKqvYaJOdxOMuClUf0C1hMYpfoaW80D3rr/iBaY7j5sX4YNsO99yPYLx54JfZWUuZsOGErGWcnT9Xxk+0VcPb/6ux5q3qF+YJaba51IT2+YsSfcdVM0A/82Ba/FmCpenUXT7lp1+8HIxYg5mHX73VJPOD8X7sexD00wBFWGAXg2wd/W/cYLIvNU1QAwT+ntV/fzzxv2oWDUeKzdU2IbUu4tqURNwD4dxa4nPCij03iCMpKOEgliYv/9Yu3CRjl+7DkcTrtxSnEy0wYZu/gbxVPpIR2SlRNu/hRVKxdlT49fg39ODM/uah48rDIHpOpdhVSyniAq+n3F6lAwn6fUnvCoz7jDZ2nOxv34QbnYtwvC+3VpgQ9vHohGuVlorKuFrf86t24cfwnBbL/A3cN6OK7zwIieePLSPtrv6nvLMaV+3Hh6AXq2bYKGOVnIUr7PLRpGpyVe0Kcdbjmrm+NrHmNRHxwID7w0p/ro6fff5mcvNFyweAmD8DQKhiR6Pfo9Pp63Ld1NsaWlo9RxcKTV4cRtiosXYnB9G9QeRX1OuE8IBEMSH83barmvEn0rWL3VNmrsClz5+hx8vWQnBj87FQu3OPSMK03Q3zoEwmkKTs275ayuht8DwVDUQXdvaaWWLpGrm1442++LqwdOH7BbBUtubimqVSDU4LYqEIqq2ALEl+Y0dvHO6NfRPd3qs9xAd0dAnawGiL4d7bYdak/4vrIqBELSMGWz/q6M3fgNczDgVGJMbdP3K3cDAN6btQXT1hZZrnvJK7OiBm7re8L1dcL1gqFQVFtDoUjaTHUw/Jwqi57wb5buNLQn1sDxI9VBrZRlXhwzf6rfdTd/IvOsnF44bukluj2RKh7Gz1FNMBT1mc6y6Sk171f17lMy/G3CGrwxfWPUcrtOBXMM/Pmi7Zbrqez2r/kiWx+Ef3vXmfjVKR20379cvAP/nRm+a+CmAqA+sNR/lfIsUkBi2fDMhbjvvOMc17njnGNx/eAC7XctCDcNmHz8kj6Y+H9DAER66C88sR1qw2436I+vVvSfSy/PaM0gPI3CpbtCjgN4vDJte6JmzDQELm7TUTywC9QmCBEJgA0BhAhP3PDwVyvx5ozIgf675btQWROs052Et2ZuwqTVxpq4ftNBb9Ka8OPm3k7je4jkEusP8BuLyvDSlOgBSGqQZr7VKGV0ILNk2yH87r0FAIwngJwsX1RZRv0gTjP9Ccqu9+zYNtEDffSscsLVW6L6x+Lpod9kUVrS6tn63sbmDbPhE+HBRPpA0twT5uazIaXUetut6ANAu3QUc664VfUFc5vU/TVmwXaMX7Hbdn3ze9K/VkV1EJUW3/VAUFrMmBnpCVffr3Fgbfj/e8YsxU3K5w2wTpWxO3bmKjPe7jkcTo1z6iFWT+RzNu1DUYxqJxU1xv3rgcOWgdUdxUAwOiXILX0lnZW6KizVwVDUd6vKJm3A/DcyX9wn0pszNuHZ79dGLbe7M2KO296YvsmxdKrdHVv9e5+wYre2v/9380Cc2LEZnv/1yTavHztw1Afhpbr3kRcjQE0U9VjjNNizW35jbH72Qow4ob3tOl/feUbcr92mqXNvv9PxzUsYhKeRemKOVbIondQDi1Nw54rFASWT0lHUixABod1e05+8BIBDFeGeSfWgPn/zAdz18RI8M35NnarLPD1+DW79wDh5jbkXUw0QmjaIlLCSUqJEN/Oklu8rgOWPX4C+Sg/FWz9vxsRV0RNfLHvsfKx4/PyoA2xQSsuD/JxN+1FRHTTslxy/D7M3Ggcm3fTuAkgptcoS+jxQfTCl7k8zq14efc9bSErDRWOVruf+xncWaI/VteJPrI9lSEpc1b8TTurQzFAJyPx5nr/5gKEKCwC8NHkDCkaNx6Kt4Tsbser0G4Nw6+/VjWcUGH536glXg2O3lUnN7SuvCmo9Vc9MWIMDR6KnAQ+GpGW+rFrtpbImiIJR4/HIVyu0x+2OBVYXVHZ/n7xsP96auRmDnp2CjcVlWmBvtb6asvPqtI245JVZ0SvoVFQbd5ZXOlBUVs059uHvcdHL1gOT3W5vU3EZLv73z9rymqCM+gza9Tarf7dgSOKsf0xNSzlau4t9q7tu+0qdp7MPhSTemrkJpZU1WjpdSWXkvd/x0WLsPlyJbL/AmRY50nquesJ1s0Lq7zaplUEuO/mY2Bupg+sHd4EQxtk1rcS6oOhlk3MOGDvA9AZ3bxXjNR0f9gwG4WnkNKhAle4AVH35QEgmvEqJ2wNuMmqUx2PD3lJc9HL4JBPuCVd76owDM82lpUqUYPzDuVtx24fuZoA0syvjaL7K31sSPjnc+sFCLQj+z08bcdLjP6JYOXFoBzMAjXOz8NUfTnd87Ua5WWiSl61ddKgmrtqDIpuT0ZB/TtMmZAEQNbpdddl/ZmuVJU5+MlKBRP+3PnTEIh1FWAeG+iBMAijVnfiqAyE0Uy5OqoMhrcJKXT9XVmXr9F/XkAyffPKyfagKhDB/8wHc+VF03fvnJ63Huc/9ZFimlkZ7Z9YW7DlciUHPTnFsizEdxfp9meuLW/UUDVSmr1YvUNzmEVeaPqcPfLnc8Pv2A9HjFYJSRqejSIkpSpqJ+p70QYxdYBu0uEixa3letg/T1xcDAHYerNC2aRmE63aR1eRVeuXVmdcTDoTLRdaGujlzT3JNIBQ1RsAu0FWPmVWBoOVnxI2LXp4ZlQoUD7c94QCijoV6UgI/F+7D0+PX4PFxq7Vjn74jRH09N720VmM2zNRSgQBQrR+jJATWPjUCz111csxt1MUpnVtg87MXoY3F7MpOftHXeHFgLif49g39Y25D3b/XDups+bhXJ+cxYxCeRk63l1VWh82K6qB2EolsK5iUnhf9FuuSUmGZE24RhIdCEt8s3WlaL72nszW6k5SAceZElc8XOcnN3LAP/55irJIxc0Nkwo94/k52J5dsU/klfYCg1n0ep1QP2a/0QmqzfioHJzcHeSA61eDhr+zTp4pNwbmaSnDbEOPgm2XbDxl+V8s96gOFUpveM6tgImjqCTcPpGypq1WurlrX8mhjl4Q/p71NtWvnbtqP/WVVkFLCJ8LpD1U1ITw/aR3Gr9iNv01YE7UtfZBiTMmpxldLdhryv628MX2jtu/Nvcttm+bi3J75AICpfzobP9x7FgDrIPxi5eRYURNEVSDousxeocUAqVgdCDXBkEU6SuTnSovP/rfLrFNipm8ojlpm9/oCQntMf/FsVlJZg5/WRW/XjrlMoxc6wvVtSHR7QlovtnF5TTBkGC8DRE8opW1D2flOd3qaN8y2fQwI18+3q9rkhj4IjxW3+X32IVNISm2fFJVWahewJRXG41hlTVCruuPEzeF5cLdWWvUQ83cpL9uf0pSMhjl+XHSSfcoJALx2zamYfN/Z+PdvTjEsN/eUDzu+rfaz+hkxvxP1dymte/w98PVzhUF4Gpl7witrglG9zVYnkqfGr8YN78zXyp4VlVSi16M/4P3ZWxLeRkMObQJ6wvVbUAde6Q8UYxZs12ZEUyUqH7221Kl7ASAvxx9VfxQIn9jVXbV6dwmem7TetofFquZwYVEpSiujl9sNXjX3yOgvaNSATT0Rqu21u60Xy+7DtZ/5b7syDfoZx7bWelmtqHcK3PyprYIJ/ed0wDNTtMFNKuOEQRKVNdEXsrWlv60cDElc/eZcXPv2/PDsj0IgL8uHykBQ64k2p+eY6QOWA0dqomars/L10l248+PFOHCkGtXBEO4eeqyWgvPRLYPw7k0DAITzM9V2WJ2gGyopJPeMWYqTn5jk+oLR3PMNhP9ON5/Z1WLtsNLKQFRPuP4Yc8QiCH/JdHGruvuTJbjvs6VRr29l1sZ9puDUuOK6PaWoCgTxp8+WWT7f7g5m1MBM65fX7DlcGXUxmmj670Uig/B9ZVVaJZ3PFhoHLFYFQlHHbP0xT3+Ou/WDhZi5odjy2KeyqqphVpu3ph4HrXrpJaRlCsX7s7dg3ibr769EZFB6ZU1Q+2ybe8LX7C6J+mz3sBjnkuOPndcthMBV/TsBSM6EevFY/eQIvPrbUx3XGXli+5hjeszUO8pqlZTv7zkLMx84V/sDhiQwvHfbqOfVeGimbScMwtPInGrQ69Ef8McxSwzLrA6caq+hmhKgBklfLN4RvXId6V/f3LsRD6vATw0c9bGAvpSb9rppDsIb6vKfu7VuZBm8hNMkjH+sP31ufRLXz56oGv78DFz39vyo5XYHVv30xWbFpVVYteswNimVBqSUKC6NTMgTb9+ImyDQjhpkdG7ZEA9eaF0PFginBazfW4qdh4x//xamXrB/TlxnPcAsxgViM12ufDAEPDthTdTFXm3p8zI/nLsVALB2TwlCSk+4zxe+QHvP5UWy/m7CfqUSiqppnn2ZraKSStz+v0UAgAO6QN6uN+ycnm2ilnVo0UD7rlbUBG17k0/p3BxbRl+Ej24ZaNue8NgBHxrblAYrrQxE9d7pA9mySudSmGZjF+80ThRjE5qNX74bc5RAauySHZGccIQHlF7w4gzc9+kybN0fPRj3qyU70OvRH7BtfzneMtUbj+4Jd/5Mnvuvn3Dpq8555rWl/g3Nd4gSZcqayBiSnabjWU0wOh1FPyZgzZ5Izfy1e0px3dvzMfz56bavpf/u2qnNW1O3u/twheUx2epbM3VtEX795lzLv61+UHFVIKR9b0tMnTH7Le5qfX774Kj36XaQqlpC9vemu431xfWDC3Dj6QX43RnhC/rj2zdFp5YNtbhBSomLTzoGn9w6yPA8t2PO0o1BeApd+uos/HdG5MBtlY4yfnn4duu0tUW45f2FlgeXBkrR+QolB1GdkarKRXpLvL5aEkkNscq7dOPDOVu0FIaP523DeiWXtkoLwiOHO6v0i5pgCAu2HEDBqPExKxQk2tDnfjIEax1bNLTMCxQOt7XNzAd89YC+1KJXzO4CpIlDMLavrErLYQfCU/me9szkSNAQZ1d4Iuqrdm7Z0LHNpVUBnP/CDPzuPWPu/KmdWxh+33GwwqbKg/POz9ENLq0OhKKqnVQHQrjl/QWGKg9uDTs+OpjNzfIhFAr3pjV1uGCyop9Gvqi0CnN1PW/mmrmndG6u/VwTlNp3KxiC1j1od0e6X5cW2DL6IsOypnnZaNskkt9p95k+T+l50k8QYhYMSfiEsP27Ww3MVC8iAKC0yn09b9Wh8hp8tnA7vli0w1VgNnbxTu3ztGZ3Cf74SbgTZPyK3VFBNQD884dw3euFWw/g6fGRtKJQSFoGck6stp9o+o6BRPaTljpcINUEZdQdPHXMCgDDsUnllJrZt2OzmO2pTSqmekz499RCnD56avj7qoTe5VVBx8Ok1QW8lJG0msqayAB1Nzn3zRvm4LVrjL3I2Q7553oNcvzYMvoiXDuoi6v1ve5SU2pJs4bZePySPlrco1LjBvVPf2qX5hjWq402tb16x8pp0KcXMAhPkapAEMu2H8IzunxQ/W3NV6cZc1hvem8BJq/ZazmqvJHyYVTTHdQP4YaiMtuZyY5UBaIGDrmhnw63tj3hb5p6jN5WUgXUnnB9lQarNlYHpfa+5jvVwU4wKSU2FR8x5Fv7fcJywMeM9cXaYLpY9pZU4qd1RdqJwynNxy5X0ukEsWjrQcPvf/goPKOiOnmE/qkf3jxA+/mhC431w1W3nNkNf7/8RPznGutbjT3bxj7I+X0irunrVad2aRG1zKqW8Ms2aQoqfa9SdTBoyNEHwgMhJ68pwv3K3YtY29Pr2a4J8psYy2XlZvkhlXSUG08vcL0tIBKE/+OKkwDAMCtqp5YNDevqe+FrgiHt1npuVmQWVLcDlJ66tA+Ob9/EEBxafTZnjRqK24eE81Ab5WYZBlWd0KEpfjswMlDKJ4ThokKvV7smUYNI9b2qToGenU8WbMMDXyzH/Z8vc90poQ9Up+pqj1sNFNyl3HX8z0/GetMvTdkQlQLlduD5Zwu348tFib+LCRgHLCeyJ9xpwq6r3pgT1ftbWx/8bgAevqh3zPX0n9OdhyqiyqJaMe8N/eDiD+duxfzNke+d/jgJRI6l5g2qd3Yqa6LHO8Ry+rGtsWX0Rdr5Pd5yjRkyDjGmF21KNpppPeHKXzI3y4+3bzxNu2irCoSw9qkR+DZBs4cmC4PwFDFP7QsYr/7VmcWA8C1PlXmgGwA0UE68+49U477PluK75ZEDwhPfrrZ8/T6PTcTJT0zStlkwarzhlqIb6oGurCqAh79agbW624pOzMci9eCi9YTrgnCrPNB05XaZbxuqV9ixZoyM5dFvVuHGdxfgS2UCGKdUCqsDeU0whKW6CiRmH9lM/qT2yOoP1mf1yNd+/vVp1qPMc7J8+PVpnW1rwX5395kYe4dzpRUAaOzQE27nxA6xe8GA2Kke+r+ZVXD3mhJUqX+L5ye5u6ACwjVyTyswXizkZPlQHQwhyy/g8wmc0KGpzbOj/Wti+LUv6BM9ucUJxxj3R7tmkV7rmmBIuxjo16WF5dgFKx/8bgAeueh4XDe4AEIIw1gGq8GxbZvkGr6z+tu+d5xzLLrnR3I+fUJYXkh2adUQW/Yfsbw1D4QrH9gF4QWjxtu+l3/8EDmO3vvpEtv19Oza4ETfOQEAP66OPpbuijGDreqBL5Zbpq6NXbzD9gJmwZYDCARDOFIVwOjv1+LNGRst75rpg9N4YvAZ64sdzw+x7vqtqMUdJZW+B3jIcfmugtHC4sjf44zRU3HOv36yXTdSDUca7pCZ78JuVgL57vmNXKXEHKmOjHHYdqC81tVe1Fz0HIfa25bPS/m8zYk1/6FhWPLoea4n1mmujBUwd4Co57Se7ZogL9vvWMPcC7zdunrEqlfErvzc/30aOSAX6w7CBaPGK73n4S/6gbJqjF28E69Oi54FzLINykFanWlOn2rihnqAWbHjMD6at811b6G5N03tOVNzLmOloyzadhArd7oL+BNpnek24j8uD/dMuun5dWOPcpI2B+Fr95Rg+Y5DABCVW/nJ/G149OuVlif9WLKzwvvZ7mAd66Cvf/i/14dLSHVt3QjZfp8h8DJTby/GmuHMSmdTz2+83rkx3M7i0sjdjGcnRE/YoSosKjMEedcP7hJVPktv5AnhQPlfV/bFezedpi0vLq1CVSCEglaNAAAjLAJqwFhfV70zpt55aZqXFRWAHN/e+NnT9+IGghK92jVBoxw/ftH3GHxw8wCc1aN1zEkthhyXb5g6Wv3bArBMz7Gb/RAIX5DogyifCFdwAIDTdXV92zTJRWVNCP+eWhi1jV+d2gHd8hthhzI+5JTOzXHnud0d34OVaS4rm6gpKHVhNRlNbYMwIDxo877PluGO/y3Wln08bxu+WboTq3eV4MrX5+CfE9fhlWmFeH36Rvxtwlos2Bx9l1Df+60eWytrguj5yPfWvbmK69+Zj5vfdyirahHRq98FIHyRUFtWF23v3nQa7jjH+Bn41amRmSb/+s2qqBx9O+p5UEqgVePIoM8P5241TMaj9oS/fm0/y3EVv/yPMZ//f3O3uh6/9MKv+9o+pl4kxBs8igyP5to0zTMNoHd2fu+2eOHXfXHPMOMsnxed1B6LHhmOfhZ3Ub0ow/9smcMqCHdTotA8OcC+siqUKwfTvTEmDrCj9lIc374pNhWX2fa2mKnBonqgWb3LOTCWUuLFyeuj6uuqgcUSpTdXH0hYlWIbv3w3th2IHrB5uLwmZopNWVVAm/zD8NyKGm2Aqx1zLp96IG6Q448aMFgbfp8P+8uqcMVrsw3LR7w4U5sYRJ8CVBMM4cGxKzBmgfP0yXbUUll2OcL6XPe3ro+u06peLHVo3gDn9W6LwmdGYvJ9ZwMID3L65s4z8JsB0b3pzyu1aoUQ+OB3A6Ied6Lv6Y3XLWd2xcmdwgfiS/pGTtjrLOp72+naupFlj7RK7YVpmJNluKugOkcpDXhSx+aWz/+lbsrq16dvhJQSUkrcde6x4RrjpiC8pekkNbNwH7rnhwP90qoAZm7Yp7X3tIKW+PDmgVrFBrfO690WA5RKNubv489/Odf2eQ9feDyG9Wpj6IH3+QTeuL4fZo0aipeuPgX3nXcclj9+Pm4bYh9UZ/t86N2+qXb38DcDOuPPF/SyrTnvBVYzqtaFekG2uyQSyD/01QrcM2apNkbgjRmbtNQ+ANp5QS8YAjq1DO83dUCkeoH4zHjru6ZObfr7D2uxYW8pXra4eDpO1zkxc8M+HFOH7y5gvAA/t2cb9D4mcjdp/kPDomaA1efoO1HPu/uPVBsGDb84eYNhZmL1Dk9ulnVFrCWmu5GtG+e6LuO73+LOuJlTTXIrmd0PHj8hBH55SkfLOyWtGjt3PHgJg/AUsbpCNt/StLJ6tzHQDYak1qPhZiBQZU3QMLCrsKhUG7yV5RMY+tx0XPX6HO3xBVsO2A5Oe3zcKlTWBLUSaltiBLF7Sirx4uTo3nI1KFAHWugPXPr0G/2gMyt9n/wRF7w4w/ZxKSVOeGwiRr4Uvc4v/v0zhvxzmuP2C4uMwZr+oPjHoT0cn+tGtl9gzILttgN3qgMhQypOrIFc7954muPj6oWM+TTxym9PwZjbBhly861KPql/m/5K6kWW32foIerbqTmeurQPfq2UzFLp1xlyXD46tjAGU9cMtE6DAeynX26Q7Udbmx7eRY8Mx61ndcWfR/REy0Y52PS3C/HbgZ3x2C964+zj8rVBhW7kZvnR3iGYyNcd7K16y9Qg3a7MWpdWkUDjxckbUFxWhZCMpO6Y33+TvPDFzsdKVZLi0qqoHp9mCbhAfOSi6Eo2DbL96NjC/s7ErUO6wecThu+JEOE0qA7NGyC/SS7uHtYDTfOycV7vtjhJyd3s2rqRYTs/F+4zBHTq5/L6wfYDz84+LvoCKJ3UXuHZhfssH/9hpXW9c5UaUFvdtXryu0jwrB8AeaC8Gm/O2IiqQFALLg8eqUaXluH9u2TbQTw+bhXGKmlw+jSiglHjUVpZg8MVNXhzhvWd1Y/mbcNrP23EeS9YH3PNM7B2adXIcj239BeoAJCnu5hs0zTP8qLDfPfSSlVNUBs3s8HFOdjnM3Zc2A30++/MTbjjo8WWj+ld0a8jLj+1o+3j1yqf83gvnt2mcZC3MAhPEatyOe/YDKLU098eA4Cz//mTlopgnuo68lqRg9OjX6/E1W/O1X4f/vwM7cCtBvH6XpwrX59jmIJYb/r6YvR69AfDyHD11tnDX63AtHVFhvXtKlaoJ2n17kCFUh9dSmnolW/ZMEfr5Yu8HvDurM24+s3whcP2AxVYvasEBaPGR108qHVsd1nUubbqWVeFQhJHqgKGmfoAY5D1uzO7Ysvoi7TyULXh9wnDWACzLfuPGAL0fk9Nsl0XCNernnjvEPQ5xjn/2HyiuvikYzCoWysIIXDXucfi6zvPsHzesOPb4rzebfGwQ6nBLL8Pf7/iJKx9agQ+v30wZo8aGrXO2D+crqX2AMCIE+x7mgFovev6c8z1p3fBvIeGW67fqnEuHr6ot3YSU/OXbzqjK97/3QBDukUsQgADu4V7hX9lCgoA4ELT5BSLHhmupZ5k+YR2S7nPMU2jJiwCgP4FLfH9PWdpKRsDngnPjKlWpGlqykVtkpeFvp2aG6Zs/usv+hjWSUSPsdXn2u4i8IERPQ2pAvq0puXb7XOD1TSfB0f2wuvX9tOW7zxUgb66qitqQPn7s4295+rFW482jfH+7wbg27vOtBycdnz7yGBRNVDM9gvH8opu9bWpDqNeRPz2rXnYfqAcm4rLcOBINcqrA7jklZ9x+/+cgzV1DINPABNW7MazFhM8mT3y9Ur8bcJavP3zZi2HeeuBI9o++WzhDrw3e4s2gNxcH3vVrhI89k14Gyp9R8T6GAGuOe3JLt1SleUTuPq0TpaPjb/7TNw73NjRYb4gtUpdtOuU0RdBeGnKBsMdngv6OF+U+31CO/ZfN6gLbrAYaH3TGQWW8yn88pQOuP3s7lj4yHDcPawHLj+1I/51ZV/HtItRI3phwzMj4x6YmcJ5eSiBGISniL4nfOn2Q/jLF9GTW1gx3/LSs0sj2V9Wjfdnb8GOg+WWA2TU4NtpEpanvlttO/21njoJw0fztuGmdxcYHrPqqQDCFw9T1+41DLxasfMwisuqDBcrQgCf/X6w4WA8q3Afnvh2taFixIUvzwRgnDTihUnrMdZF3XSrNKFnv1+DPo9NjBoYZu7pAYAvLQYkDusVXbLOilqO0s7H87bhsXGrtN+dZpUDwjmEPds1wfi7z0J/h3w4p9kX77+gp23ZuZaNcvDf6/u7mqI4L9uP0wpaRpXUA8K9WFed1glzHxyGL/8w2DKNQ+8SZRbHbroeU7U36qELe2G4RYnA2phw91lRy8qrgxjaqy2+/MNg/PPKvhh/95na52DUyF5RufCtGufirqHHAoD2PxC+EHjowuPxya2DMOS4fIy5bRAm3jsEQDhIvLivMZhXK8mYgxQ1OBZC4NlfnYjv/ngmGudmGS4srh9cUJu3b9CmaR7mPzQMcx4cGp4Yw8Ed5xyLB0ZEKuvoe8J/PcA6yAKgpbw0ycuOGvh2bJvGOF+5Y6HvfddXqVB70Nsq++TEjs2w6okLMPpXJxq2ld8kF3/75Yl4+rITtPSpgV1b4QxdPn48TtXdobOabOecnvmGqj5n/WMahj43Hac+NQm9/zoRy3dYX5jsK6vC7I37MPz56bjqjXAnQ2VNCHd8tBhv6Erbmv35gp4AIseyLfuO4Dvl2PLqtI1aJaBYk60dPFId1WEx/PkZ2nFqc4yUm6G9jMHsofIaPHlpH+1Ojbn03KxRQzH68pNwg+4OR6eWDXD94C7oc0yzqJ7dPKUUr3oYVr975mDdbPbGfej16A/a7x/N26adO5vkZmH0r06yeyqA8J2cbvmN8eUfBuOxX/Q2jONQ9Whj3TsekhKjRvZC68a5uO+84/DcVfa54CohRK0GE2b6wMyjVd0LAJMr+mDvsgRN0GDuqVWNX74bz0xYgzELtlvOuKjWbNXnlAeCIcOAq7d/3uwqmCwqrbSdQMQuX/utnzfjrZ/DdwGa5GWhtDKA/Ueq8LGpqodPCLRqnIt7hx+npbU45UP7hMCnC7Zh+vpiTFixJ2bbAeBfP67DQ6ae3fdnhydcMefjW6UbdGjeAKcVtMCCLZE7Fm/feBpenVaIf05chzev64eOLRpqFwp6C02lBAFgsi4n0c3kLhPuPguHyqtRZfo7/++Wgdiwtwy/eCV8V+Ps4/K1GSJrM0AyGdo1y9Nyvoccl48Z64tx0Ynt8bszC3D5a3O0HlB1oF+O7vas2tN425DuuG5QAR75eiWuH9wl7hzyD28egD99tgx52X5DzqmqXOmR7NclHDD2OaYZrh3UBe/N3mI7kPWEDs0w84Fzo9JuAGBw91aGXmyV+cSu9oRfPaCzIddVX5VEn38//Pg2yPH70CjXH3cPmh31YqsmGMKQ4/Jx21nRPflW9Pmz51pMCKS677ye6NelBQZ1a2lZPerl35yCnzfsM/xd9Bds6udD/zdvmJMVld6i3q1T6yhP+r8haF+HuwXNG+Zg7VMjsP1AOT6Ys1WboAkIX6i/p8xO2qtdE1c1olX9n54ctcw8nsbKnecei7mb9mvB9mcL3Zc7vOOc7lq5xT98tNgy9erOjxfjzo9jb0s/XqFzy4Z46MLjMbx3W+2icNv+cnyzNDwYtE2TXO3i6fFL+qDPMc3wwJfL8cM9Q2znJVB7wtXP9xOX9sHl/TpiQNeWOK2gJd6dtQWTdRVdyqoC+GTeNkNZYNWDY1cAAGb+5VzDBeCcB4di58EKXKFL0WyopE2qxwB9mdAsn8BLV5+CU7s015bNfOBc+HwCZ4yeqnUgpIJ6zcIe8czCIDxF3NaM/deVfVFaWYNnv19reE6nlg1cj7ZXDzob9paifXP7oETfi/Nz4b6oGfTMgZ2VP322DKtMAzRX7ypBRU3QdnpnvSHH5WP88t2GSVpO794KszfuNxyMT+3cHPvKqh3TSEoqa/CXL1c4vl4oJA3l55ZuP4QNe0vxwJfL8fYNp2FW4T7twmVfWRUKWjXUct/tSr6pvfeXnXwM2ionsTvPPRbXDOyslVHK8gnLQTvd8xsZ6l7f8kF0RYI/nXccerRtbHkL2ypwBMInLH3O9B/O6a4F4Q9fbJ9Oki6vXXMq1u4p1XrNlj9+PvzKWUW9+MnyCfzujK54Z9ZmQw90gxy/qx4mvZM6NsPyHYdxVo98zH84Oq3l4QuPxzMT1qBjy+hgTf17OwW75nresXRp1Qhv39Bfq0ih9vqpvdy3Wnwu9IQQWP/MyLhe061svy+uAbVqEHBSjElW/D6h9Z7mN8nF8e2bYo1uDExett9ybILqF32PwfzNBzBqpLG+fa/2xu/EP68wfjZ6uKhu9K8r+6K8OoCvluzEPy4/CV1bN8KqXSW49NVZ6NC8AfKy/ejRtgmeuuwEPHFJH3R7aAIAYPaDkfSr7m0axxWE14aa+nTHOcdG1b5vkptlKDH58S0DcWzbxlrKEwDceEaBoea5091RKx1bNMCOg+Hzkt8n8ODIXujZronlbKydWzXE9/echZEvzTSMhRBC4KrTOuEqm9QUlfqdUNPM8rL92t2UM45tjcHdWqHvkz9qdzBPeGyi4/Zysnza8fm9m05DswbZaN+sQdT4Datc60cv7o2DR6pxv3IXQk/97psnwkoVu1558iYG4Snwjx/WRk3uYCcny4ebzuiKm87oij/8bxG+Xxnu0R1/91nYWFSGX/5ndowtRARCMuZMgqob310QNUPXcz+G85V7tm2Cv4zsaQiU1WDIHIADkfSQN6/rF/WY2XNX9o1Kyzj7uHzM3rjfUNt57B3hPOW//7BWq+lsNk+XomK2cudhfLFoR1TvcpsmuXhjxiYs2XYI45buxOO6OutFpVU4vXsrnN+nHb5fuRttmlgPBFQvNm45qxtO0NW1bq47mDfI9qO0KoDXr+1nmBWwrCqALq0aYqtukOvEe4douY2P/aI3bjqjK4pKK3FCh6ZaqcYL+rSNqo9qpr+lOahbK/z8l3MhJeKewTEVGuVmGQYY6tuofoKz/AIPXdgLdw871nbApluf3jbYckbG3CwfqgIh3DqkG07r2tJytr6WjcJta93YPq+zNob2aoNjmuVh1+FKQ9nOAQUtE/o6yab2asfb7vdvOg0D/jZFm6zEzvi7z8SBI9VolJuF5y0m9mjWIBuNc7NQVhXAvIeGaT2uVj6+dSC+X7EHNcEQxizYjgbZfvz9ipO0Hkx9ak/fTs3x9g39o9JYfL5wfvnG4jK00c02OqCgpeHYtuyv5+OxcSvx9VL70oBufXTLQPRq10SrAmFVjm3ho8NRWR1C3yd/BBCeDEZtxwuT12PR1oNo2TAHf/vliXjoK+fOCzvf3nUmTtGNVTHn7Zv1atcEo0b2wpX97Acm2lGDb7uLX58vPKbl2e/tS5DqPXpxZBIg/UVDbpYPtw3phpEntDMMENa7+cyubpudMnnZfrx5XT+c0tk+FZG8J+ODcCHECAAvAfADeEtKOTrNTYritjekW34j9GgT6eF77dp+eH/2FhyuqEHTvGyc0rkFXrr6ZMspc+2oPRsNsv14+KLj8eGcrbYl2sw5x2rA9+vTOhny/XKzfHhgRE/LgaX6Gst2OeGqMbcNQl62H1P/dDaGPjddW36iEvhst+j1/suIXvh1/06WkzHsdKgWYzfY9Lvlu7Ueu8ctJjqavXE/Pr51UFTKip5a8sppevcxvx+EKWuKtMFL2X6B1o1z8dCFx+PsnvlYtv0Qrnt7PoBw7/jvz+6Gkooa3KAEAW2a5OG7P56Fx75ZiffnbMW/f3NqzLSDbNPjTpUtvEzNZc3yCWT5fYaLm9pqkOOPmgYZAOY/NBxVwfDn1i43/u5hPVDQyrl0YW0IITDtz+dgwordhpraLufc8YxLTj4Gm/eV4d7hx8VeWSe/SS5uPL0gqiqGWZ9jnHvYgXBwXVYZcAzAAeD07q1xevfWOFxeg7xsP0aN7OV4gTfseOue+TOObR0VnN9wegEGd2+F539cj9KqGjRtkIUXrz4F9w4/znEyGdXvh3TDzkMVWn73gIKWOKtHa+w6XBn1WjlZPrx09cl4fNwqBEMSs0YNRW6WH7lZfjzzyxMMF3XqNOCq3w7sjMXbDuJQeTUev6QPpq0rRq92TbB6V4lhTIrZIxcdH1ddZyD8Gb89RqBu/9zw/00cJv3qXxA7AH1gRE/celY327xrIYTj8d7OnAeHup4gK1nOT/AxiZIvo4NwIYQfwKsAzgOwA8ACIcQ4KWV8BVCTTA0ibj+7O4Yf30bLN/vw5gE4o3trvDZ9I+Zs3I//WYzWN4/EvvikY1BSGcDFJ7bXeiCeurQPTuzYHD+tK8Llp3bExuIyLN52SJtMJ8fvw8onLlBu/7bB6aOnxtX+XOU24J8v6Il/TlyHFg1zkJftx2vXnIp/Ty1E84bZmL1xf9Tz7v10adSyob3aYF9ZFXq1a4JTlSv2bvmN8c6N/TFv0wE0ys3CKUptZ6ua0wBQ0LoR/nPNqVo5qO75jVBRHcSuw5Xoc0xTrNpVgl/374RPlYGaar6xmd8nEAxJ24FSAHC3bnCdHbUKgFOudZ9jmqHPMc20spSNc7Mw58Fh2uNn9cjHs786EWMX70CW34cHR1qfBB77RR88eOHxrvJ+zXc2MpV6N8ft9Ot1ES7v53ynIDfLjyv7O986r63cLD9+eYqxl9BqLIKXNc7NcjXVuJkQwhAc1oVdXXY75sA0UY5r2wSvm+4IFrRuhH9d2Rf3K7NkvnvjaTihQzMs2noAt/9vMRrm+PGPK07CxSeFe+OvGbgfzRtmazP22rn05A649OToC5hrBtqXdlT968pIys51Su78aQUtcWX/jnjux/W4sn9H/OmzZXjjun4orw5i9+FKrSykm2NkInRo3gB/OKc7rnL47p3SqQUeHNkLl/friFenFYbzxO8bguHPz0Dj3Cx8+vtB6N2+aVLK+bVv5t069uRdQsYzl63HCCEGA3hcSnmB8vuDACClfNbuOf3795cLFzrnVybatHVFeP2njXjjun5o3jAH3y3fhU3FR3D3sLrVmi4YNR63nNkVj1xsfcJ7YdJ6fLZwO64d1AV3nhs5UE5Zsxdb9pfjqe9Wo0ebxnjuqr7YcbACJRU1GDU2cltSHXD4n2tOxYUnhqs3LNt+CC0b5RhyXmuCIbw8ZQOmrCmKqmsOAPeddxwa5vgxZU0RPrltkKv3JqV0PFBKKTF+xW40zs3CkB758PkE9hyuRItG2dhYdAS92jXR8jRnPnAufvXabDz2i95onJuFotIqXNmvIxZvO4jLXwtfEOU3ydXqYP/14t5aLV43eX0fzNmCv36zCuueHhGztuvOQxU4Y/RUtGuah7kPDXNct65CIYluD02AEMDmZ9OTn5gIhUVlGP78dNw99Fjcd350DmZ9V1kTRK9Hf0Cnlg0w84Hoko+UeYIhiR0Hyw21tJduP4TLXp2Fkzo2w7i7zkxj6+oHKSWOVEdqpsc6pxAlgxBikZTSti5upgfhVwAYIaW8Rfn9OgADpZR32T0nHUG4V1UHQpCQhsBxze4SdGzRAI1zs1BSGcC6PaU4pXPzuEomlVUFMGH5bizZfhDtmjbAPTFKSCXL7sMVCAQlOrVsaHsAllJix8EKdGzRAHtKKrG5+AgGdG2JYx/+Hse1bYwf/+/shLYpGJJ4cOxy3HB6gavb6nX17ykbMPT4Nil5rWQqLCpF19aNM65XOFG+XLQDg7u3siz5SPVDdSCE+z9fhruH9cCxbRrHfgIReR6D8PDy2wDcBgCdO3fut3Xr1qhtEemVVtYg2++r8wBAIiIiOjrFCsIzbMhPlJ0A9AliHZVlBlLKN6WU/aWU/fPzvTW9MXlTk7xsBuBERESUNJkehC8A0EMI0VUIkQPgagDj0twmIiIiIiJHGV0dRUoZEELcBWAiwiUK35FS2tdUIiIiIiLygIwOwgFASjkBwIR0t4OIiIiIyK1MT0chIiIiIso4DMKJiIiIiFKMQTgRERERUYoxCCciIiIiSjEG4UREREREKcYgnIiIiIgoxRiEExERERGlmJBSprsNKSWEKAawNd3tSJPWAPaluxEZgvvKHe4nd7if3OO+cof7yT3uK3e4n9yJZz91kVLm2z141AXhRzMhxEIpZf90tyMTcF+5w/3kDveTe9xX7nA/ucd95Q73kzuJ3E9MRyEiIiIiSjEG4UREREREKcYg/OjyZrobkEG4r9zhfnKH+8k97it3uJ/c475yh/vJnYTtJ+aEExERERGlGHvCiYiIiIhSjEF4BhNCdBJCTBNCrBZCrBJC3KMsbymEmCSE2KD830JZ3ksIMUcIUSWEuN+0rXeEEEVCiJXpeC/Jlqh9Zbed+iKB+ylPCDFfCLFM2c4T6XpPyZLI75/yuF8IsUQI8V2q30syJfg4tUUIsUIIsVQIsTAd7ydZEryfmgshvhBCrBVCrBFCDE7He0qWBB6neiqfJfVfiRDi3jS9rYRL8Gfq/5RtrBRCfCKEyEvHe0qGBO+ne5R9tMrNZ4npKBlMCNEeQHsp5WIhRBMAiwBcBuBGAAeklKOFEKMAtJBS/kUI0QZAF2Wdg1LKf+m2NQRAGYAPpJQnpPadJF+i9pXddqSUq1P+ppIggftJAGgkpSwTQmQD+BnAPVLKuSl/U0mSyO+fsr37APQH0FRKeXHq3klyJfg4tQVAfyllvatlnOD99D6AmVLKt4QQOQAaSikPpfQNJVGiv3vKNv0AdgIYKKWsF3OJJPB43gHhY3hvKWWFEOIzABOklO+l+j0lQwL30wkAxgAYAKAawA8AbpdSFtq9NnvCM5iUcreUcrHycymANQA6ALgUwPvKau8j/EGBlLJISrkAQI3FtmYAOJCCZqdFovaVw3bqhQTuJymlLFN+zVb+1asr/kR+/4QQHQFcBOCt5Lc8tRK5n+qzRO0nIUQzAEMAvK2sV12fAnAgaZ+pYQA21pcAHEj4fsoC0EAIkQWgIYBdyW196iRwPx0PYJ6UslxKGQAwHcCvnF6bQXg9IYQoAHAKgHkA2kopdysP7QHQNl3t8qJE7SvTduqduu4nEU6vWAqgCMAkKWW93E9AQj5TLwJ4AEAoGe3zigTsJwngRyHEIiHEbclpZfrVcT91BVAM4F0RTm96SwjRKGmNTbMEnvuuBvBJYlvnHXXZT1LKnQD+BWAbgN0ADkspf0xea9Onjp+nlQDOEkK0EkI0BHAhgE5OT2AQXg8IIRoD+BLAvVLKEv1jUkqJetYDWReJ2ldO26kPErGfpJRBKeXJADoCGKDcqqt36rqvhBAXAyiSUi5KXivTL0HfvTOllKcCGAngTiWNrl5JwH7KAnAqgNeklKcAOAJgVDLamm4JPJ7nALgEwOcJb6QHJOAY1QLhXuGuAI4B0EgIcW2Smps2dd1PUso1AP4O4EeEU1GWAgg6PYdBeIZT8m2/BPCRlHKssnivkuOk5joVpat9XpKofWWznXoj0Z8p5Vb4NAAjEtzUtEvQvjoDwCVKvvMYAEOFEP9LUpPTIlGfKaVHDlLKIgBfIZx7WW8kaD/tALBDd+fpC4SD8nolwcepkQAWSyn3Jr6l6ZWg/TQcwGYpZbGUsgbAWACnJ6vN6ZDAY9TbUsp+UsohAA4CWO+0PoPwDKYMfnsbwBop5fO6h8YBuEH5+QYA36S6bV6TqH3lsJ16IYH7KV8I0Vz5uQGA8wCsTXiD0yhR+0pK+aCUsqOUsgDhW+JTpZT1ppcpgZ+pRsqgKSjpFecjfPu3Xkjg52kPgO1CiJ7KomEA6sXAcVUSzn2/QT1MRUngftoGYJAQoqGyzWEI503XC4n8PCmDNiGE6IxwPvjHjk+QUvJfhv4DcCbCt0eWI3zbYynCOUitAEwBsAHAZAAtlfXbIdxLUgLgkPJzU+WxTxDO9apRlt+c7vfnxX1lt510vz8P7qeTACxRtrMSwF/T/d68uq9M2zwHwHfpfm9e3E8AugFYpvxbBeDhdL83L+4n5bGTASxUtvU1wlUd0v4ePbqvGgHYD6BZut+Xx/fTEwh3pKwE8CGA3HS/P4/up5kIX/QuAzAs1muzRCERERERUYoxHYWIiIiIKMUYhBMRERERpRiDcCIiIiKiFGMQTkRERESUYgzCiYiIiIhSjEE4EREBAIQQjwsh7nd4/DIhRO9UtomIqL5iEE5ERG5dBoBBOBFRArBOOBHRUUwI8TDCs8EVAdgOYBGAwwBuA5ADoBDAdQhPAPOd8thhAJcrm3gVQD6AcgC3Sinr1cyoRETJwiCciOgoJYToB+A9AAMBZAFYDOB1AO9KKfcr6zwNYK+U8t9CiPcQntHzC+WxKQBul1JuEEIMBPCslHJo6t8JEVHmyUp3A4iIKG3OAvCVlLIcAIQQ45TlJyjBd3MAjQFMND9RCNEYwOkAPhdCqItzk91gIqL6gkE4ERGZvQfgMinlMiHEjQDOsVjHB+CQlPLk1DWLiKj+4MBMIqKj1wwAlwkhGgghmgD4hbK8CYDdQohsANfo1i9VHoOUsgTAZiHElQAgwvqmrulERJmNQTgR0VFKSrkYwKcAlgH4HsAC5aFHAcwDMAuAfqDlGAB/FkIsEUJ0RzhAv1kIsQzAKgCXpqrtRESZjgMziYiIiIhSjD3hREREREQpxiCciIiIiCjFGIQTEREREaUYg3AiIiIiohRjEE5ERERElGIMwomIiIiIUoxBOBERERFRijEIJyIiIiJKsf8HGpU1piYM44gAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.set_index(dataset['date'])\n",
        "dataset = dataset.drop('date', axis=1)"
      ],
      "metadata": {
        "id": "sLN0BB4ut5Up"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = dataset['turnover_(lacs)']\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZYYUhHXujHQ",
        "outputId": "cc0bfd3d-f3a9-4aa0-df18-2e9abb505098"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "date\n",
              "2018-09-28     7162.35\n",
              "2018-09-27    11859.95\n",
              "2018-09-26     5248.60\n",
              "2018-09-25     5503.90\n",
              "2018-09-24     7999.55\n",
              "                ...   \n",
              "2010-07-27      694.98\n",
              "2010-07-26      780.01\n",
              "2010-07-23      340.31\n",
              "2010-07-22      355.17\n",
              "2010-07-21      803.56\n",
              "Name: turnover_(lacs), Length: 2035, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "df = scaler.fit_transform(np.array(df).reshape(-1, 1))"
      ],
      "metadata": {
        "id": "f03Dn1jer4T4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdyW30q9ynjR",
        "outputId": "49dc5422-9a3a-4404-bf87-15005c0c8c13"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.7139219 ]\n",
            " [ 1.74192305]\n",
            " [ 0.29512567]\n",
            " ...\n",
            " [-0.77898191]\n",
            " [-0.77573002]\n",
            " [-0.67760642]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_frac = 0.75\n",
        "train_len = int(train_frac*len(df))\n",
        "\n",
        "train_data = df[:train_len]\n",
        "test_data = df[train_len:]\n",
        "\n",
        "print(len(train_data), len(test_data))"
      ],
      "metadata": {
        "id": "muxn_l12yqn1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b764b4a-9a29-42c3-c72d-aa3b3cd55d74"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1526 509\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_target_split(df, step):\n",
        "  X = []\n",
        "  Y = []\n",
        "\n",
        "  for i in range(len(df) - step - 1):\n",
        "    X.append(df[i:(i + step), 0])\n",
        "    Y.append(df[i + step, 0])\n",
        "  \n",
        "  X = np.array(X)\n",
        "  Y = np.array(Y)\n",
        "\n",
        "  return X, Y\n",
        "\n",
        "train_features, train_targets = feature_target_split(train_data, 75)\n",
        "test_features, test_targets = feature_target_split(test_data, 75) "
      ],
      "metadata": {
        "id": "tJD8qKV2jkDc"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_features[0], train_targets[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeUsJ-NOl7kS",
        "outputId": "fac5d147-f23d-4059-bab2-8b1f2bc03ea5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.7139219   1.74192305  0.29512567  0.35099434  0.89713089  1.90159411\n",
            " -0.15257216  0.49538194  0.77586545  2.3819181   1.33534002  0.83941525\n",
            "  2.89525998 -0.25322331 -0.00946694  0.60725715  0.93307898  1.89038974\n",
            "  0.87823665  0.13493159 -0.13560148  0.3658467   0.17287108  0.08520781\n",
            " -0.05199979  0.88440562  0.05292522  0.6533417   0.48293239  0.12254332\n",
            "  0.14740521  0.18765123 -0.2677124   0.08871793  0.17016628  0.4772558\n",
            "  0.87388401  2.06329815  6.22052289  1.53564662  0.14111588 -0.01707147\n",
            "  1.23972865  0.37124537  0.37362192  0.38197706  0.70979029  1.32047015\n",
            "  0.90187306  0.85231778  1.02125433  1.07329776  0.46948714 -0.01934736\n",
            " -0.08038931  0.49634481  0.33778325  0.56000622  1.33486077  3.19137053\n",
            "  1.27819991  0.35430313  1.75451703  0.43878016  0.43474484  0.36410696\n",
            "  0.5564392   0.85486284  1.06248948  2.78801313  0.06877109  1.03160087\n",
            "  1.34963216 -0.12869941 -0.15112347] 1.2189830501709675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features = train_features.reshape(train_features.shape[0], train_features.shape[1], 1)\n",
        "test_features = test_features.reshape(test_features.shape[0], test_features.shape[1], 1)"
      ],
      "metadata": {
        "id": "-QHTJslmmO6h"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_features[0])\n",
        "print(train_features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3asQL98cnLTZ",
        "outputId": "5086b10f-6f22-4465-a53c-5d91e24ca730"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.7139219 ]\n",
            " [ 1.74192305]\n",
            " [ 0.29512567]\n",
            " [ 0.35099434]\n",
            " [ 0.89713089]\n",
            " [ 1.90159411]\n",
            " [-0.15257216]\n",
            " [ 0.49538194]\n",
            " [ 0.77586545]\n",
            " [ 2.3819181 ]\n",
            " [ 1.33534002]\n",
            " [ 0.83941525]\n",
            " [ 2.89525998]\n",
            " [-0.25322331]\n",
            " [-0.00946694]\n",
            " [ 0.60725715]\n",
            " [ 0.93307898]\n",
            " [ 1.89038974]\n",
            " [ 0.87823665]\n",
            " [ 0.13493159]\n",
            " [-0.13560148]\n",
            " [ 0.3658467 ]\n",
            " [ 0.17287108]\n",
            " [ 0.08520781]\n",
            " [-0.05199979]\n",
            " [ 0.88440562]\n",
            " [ 0.05292522]\n",
            " [ 0.6533417 ]\n",
            " [ 0.48293239]\n",
            " [ 0.12254332]\n",
            " [ 0.14740521]\n",
            " [ 0.18765123]\n",
            " [-0.2677124 ]\n",
            " [ 0.08871793]\n",
            " [ 0.17016628]\n",
            " [ 0.4772558 ]\n",
            " [ 0.87388401]\n",
            " [ 2.06329815]\n",
            " [ 6.22052289]\n",
            " [ 1.53564662]\n",
            " [ 0.14111588]\n",
            " [-0.01707147]\n",
            " [ 1.23972865]\n",
            " [ 0.37124537]\n",
            " [ 0.37362192]\n",
            " [ 0.38197706]\n",
            " [ 0.70979029]\n",
            " [ 1.32047015]\n",
            " [ 0.90187306]\n",
            " [ 0.85231778]\n",
            " [ 1.02125433]\n",
            " [ 1.07329776]\n",
            " [ 0.46948714]\n",
            " [-0.01934736]\n",
            " [-0.08038931]\n",
            " [ 0.49634481]\n",
            " [ 0.33778325]\n",
            " [ 0.56000622]\n",
            " [ 1.33486077]\n",
            " [ 3.19137053]\n",
            " [ 1.27819991]\n",
            " [ 0.35430313]\n",
            " [ 1.75451703]\n",
            " [ 0.43878016]\n",
            " [ 0.43474484]\n",
            " [ 0.36410696]\n",
            " [ 0.5564392 ]\n",
            " [ 0.85486284]\n",
            " [ 1.06248948]\n",
            " [ 2.78801313]\n",
            " [ 0.06877109]\n",
            " [ 1.03160087]\n",
            " [ 1.34963216]\n",
            " [-0.12869941]\n",
            " [-0.15112347]]\n",
            "(1450, 75, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_features[0])\n",
        "print(test_features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCUjUkGrp9NC",
        "outputId": "baf03aad-3a11-4c95-db15-4a996a671cb0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.31658054]\n",
            " [-0.19412244]\n",
            " [-0.06163074]\n",
            " [ 0.3012443 ]\n",
            " [-0.62959612]\n",
            " [-0.32706056]\n",
            " [-0.30131458]\n",
            " [-0.35543914]\n",
            " [-0.45736391]\n",
            " [-0.62662433]\n",
            " [-0.6942948 ]\n",
            " [-0.39742927]\n",
            " [-0.33775724]\n",
            " [-0.58580059]\n",
            " [-0.49554193]\n",
            " [-0.61681394]\n",
            " [-0.63363144]\n",
            " [-0.47729544]\n",
            " [-0.52182844]\n",
            " [-0.48585628]\n",
            " [-0.54599881]\n",
            " [-0.455204  ]\n",
            " [ 0.11421663]\n",
            " [ 0.02373914]\n",
            " [-0.44665411]\n",
            " [-0.58575682]\n",
            " [-0.50347253]\n",
            " [-0.53991737]\n",
            " [-0.57854401]\n",
            " [-0.60306452]\n",
            " [-0.65816508]\n",
            " [-0.63079096]\n",
            " [-0.54813683]\n",
            " [-0.67768082]\n",
            " [-0.5221939 ]\n",
            " [-0.34360014]\n",
            " [-0.58017871]\n",
            " [-0.59039176]\n",
            " [-0.5960771 ]\n",
            " [-0.58896714]\n",
            " [-0.59677519]\n",
            " [-0.61173259]\n",
            " [-0.73280327]\n",
            " [-0.6219522 ]\n",
            " [-0.67085534]\n",
            " [-0.61876158]\n",
            " [-0.48435507]\n",
            " [-0.10371278]\n",
            " [-0.64276563]\n",
            " [-0.65753046]\n",
            " [-0.63463809]\n",
            " [-0.37448438]\n",
            " [-0.43940628]\n",
            " [-0.54341217]\n",
            " [-0.47519899]\n",
            " [-0.52087432]\n",
            " [-0.56085554]\n",
            " [-0.62114688]\n",
            " [-0.68661806]\n",
            " [-0.65087348]\n",
            " [-0.53383594]\n",
            " [-0.50684916]\n",
            " [-0.24843519]\n",
            " [-0.59189078]\n",
            " [-0.82520432]\n",
            " [-0.6569965 ]\n",
            " [-0.27795609]\n",
            " [-0.58534104]\n",
            " [-0.55723163]\n",
            " [-0.20742763]\n",
            " [ 0.05667168]\n",
            " [ 0.44711341]\n",
            " [-0.20318003]\n",
            " [-0.57708219]\n",
            " [-0.67273514]]\n",
            "(433, 75, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Build The Model"
      ],
      "metadata": {
        "id": "nRFQDHcZ6ivK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(train_features.shape[1], train_features.shape[2]))\n",
        "prog = LSTM(64, activation='tanh', return_sequences=True)(inputs)\n",
        "prog = LSTM(128, activation='tanh', return_sequences=True)(prog)\n",
        "prog = LSTM(256, activation='tanh')(prog)\n",
        "prog = Dense(128, activation='tanh')(prog)\n",
        "prog = Dropout(0.2)(prog)\n",
        "prog = Dense(64, activation='tanh')(prog)\n",
        "prog = Dropout(0.2)(prog)\n",
        "prog = Dense(1, activation='tanh')(prog)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=prog)\n",
        "\n",
        "model.compile(optimizer=Adam(0.001), \n",
        "              loss='mean_squared_error', \n",
        "              metrics=['mae'])"
      ],
      "metadata": {
        "id": "LoJfQO0VqXhr"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KEm1WXXsj0t",
        "outputId": "d437cdfd-6773-4614-aee4-e844057dc771"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 75, 1)]           0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 75, 64)            16896     \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 75, 128)           98816     \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 256)               394240    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 551,169\n",
            "Trainable params: 551,169\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model checkpoint callback\n",
        "set_cp = tf.keras.callbacks.ModelCheckpoint(filepath='/content/best_model.h5',\n",
        "                                            monitor='loss',\n",
        "                                            save_best_only=True,\n",
        "                                            verbose=1)\n",
        "\n",
        "# reduce LR callback\n",
        "set_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss',\n",
        "                                              min_lr=0.0001,\n",
        "                                              patience=6,\n",
        "                                              verbose=1)\n",
        "\n",
        "# custom callback to stop when the model reaches the expected accuracy\n",
        "class Specific_Stopper(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, exp_loss, exp_val_loss):\n",
        "    super(Specific_Stopper).__init__()\n",
        "    self.exp_loss = exp_loss\n",
        "    self.exp_val_loss = exp_val_loss\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    loss = logs.get('loss')\n",
        "    val_loss = logs.get('val_loss')\n",
        "    if (loss >= self.exp_loss) and (val_loss >= self.exp_val_loss):\n",
        "      print(f'The model has reached expected loss. \\n akurasi : {round(loss, 2)}, akurasi validasi : {round(val_loss, 2)}. Proses learning dihentikan')\n",
        "      self.model.stop_training = True\n",
        "\n",
        "set_stop = Specific_Stopper(0.5, 0.5)"
      ],
      "metadata": {
        "id": "hk52aUO_sx9z"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x=train_features,\n",
        "                   y=train_targets,\n",
        "                   epochs = 500,\n",
        "                   callbacks=[set_cp, set_lr, set_stop],\n",
        "                   validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAn3MhlJtCSN",
        "outputId": "636bea19-7f31-4fd8-f82e-ae6ab14e0f64"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.9370 - mae: 0.5105\n",
            "Epoch 1: loss improved from inf to 0.93696, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 34s 686ms/step - loss: 0.9370 - mae: 0.5105 - val_loss: 0.3540 - val_mae: 0.4291 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.9028 - mae: 0.4904\n",
            "Epoch 2: loss improved from 0.93696 to 0.90279, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 23s 630ms/step - loss: 0.9028 - mae: 0.4904 - val_loss: 0.3147 - val_mae: 0.3766 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8984 - mae: 0.4736\n",
            "Epoch 3: loss improved from 0.90279 to 0.89845, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 595ms/step - loss: 0.8984 - mae: 0.4736 - val_loss: 0.3067 - val_mae: 0.3767 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8907 - mae: 0.4798\n",
            "Epoch 4: loss improved from 0.89845 to 0.89068, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 30s 805ms/step - loss: 0.8907 - mae: 0.4798 - val_loss: 0.2996 - val_mae: 0.3760 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8919 - mae: 0.4738\n",
            "Epoch 5: loss did not improve from 0.89068\n",
            "37/37 [==============================] - 22s 596ms/step - loss: 0.8919 - mae: 0.4738 - val_loss: 0.2852 - val_mae: 0.3592 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8770 - mae: 0.4671\n",
            "Epoch 6: loss improved from 0.89068 to 0.87703, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 21s 560ms/step - loss: 0.8770 - mae: 0.4671 - val_loss: 0.2931 - val_mae: 0.3824 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8761 - mae: 0.4675\n",
            "Epoch 7: loss improved from 0.87703 to 0.87612, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 602ms/step - loss: 0.8761 - mae: 0.4675 - val_loss: 0.2659 - val_mae: 0.3319 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8724 - mae: 0.4619\n",
            "Epoch 8: loss improved from 0.87612 to 0.87244, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 28s 756ms/step - loss: 0.8724 - mae: 0.4619 - val_loss: 0.2593 - val_mae: 0.3382 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8685 - mae: 0.4613\n",
            "Epoch 9: loss improved from 0.87244 to 0.86849, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 30s 812ms/step - loss: 0.8685 - mae: 0.4613 - val_loss: 0.2650 - val_mae: 0.3347 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8624 - mae: 0.4536\n",
            "Epoch 10: loss improved from 0.86849 to 0.86241, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 32s 864ms/step - loss: 0.8624 - mae: 0.4536 - val_loss: 0.2598 - val_mae: 0.3430 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8677 - mae: 0.4591\n",
            "Epoch 11: loss did not improve from 0.86241\n",
            "37/37 [==============================] - 34s 904ms/step - loss: 0.8677 - mae: 0.4591 - val_loss: 0.2555 - val_mae: 0.3520 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8638 - mae: 0.4513\n",
            "Epoch 12: loss did not improve from 0.86241\n",
            "37/37 [==============================] - 22s 586ms/step - loss: 0.8638 - mae: 0.4513 - val_loss: 0.2571 - val_mae: 0.3370 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8617 - mae: 0.4518\n",
            "Epoch 13: loss improved from 0.86241 to 0.86166, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 20s 555ms/step - loss: 0.8617 - mae: 0.4518 - val_loss: 0.2600 - val_mae: 0.3610 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8539 - mae: 0.4499\n",
            "Epoch 14: loss improved from 0.86166 to 0.85393, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 585ms/step - loss: 0.8539 - mae: 0.4499 - val_loss: 0.2601 - val_mae: 0.3439 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8530 - mae: 0.4462\n",
            "Epoch 15: loss improved from 0.85393 to 0.85300, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 591ms/step - loss: 0.8530 - mae: 0.4462 - val_loss: 0.2400 - val_mae: 0.3339 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8531 - mae: 0.4469\n",
            "Epoch 16: loss did not improve from 0.85300\n",
            "37/37 [==============================] - 20s 555ms/step - loss: 0.8531 - mae: 0.4469 - val_loss: 0.2421 - val_mae: 0.3288 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8528 - mae: 0.4482\n",
            "Epoch 17: loss improved from 0.85300 to 0.85282, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 23s 633ms/step - loss: 0.8528 - mae: 0.4482 - val_loss: 0.2526 - val_mae: 0.3289 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8531 - mae: 0.4443\n",
            "Epoch 18: loss did not improve from 0.85282\n",
            "37/37 [==============================] - 22s 595ms/step - loss: 0.8531 - mae: 0.4443 - val_loss: 0.2434 - val_mae: 0.3210 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8587 - mae: 0.4577\n",
            "Epoch 19: loss did not improve from 0.85282\n",
            "37/37 [==============================] - 21s 580ms/step - loss: 0.8587 - mae: 0.4577 - val_loss: 0.2430 - val_mae: 0.3246 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8561 - mae: 0.4451\n",
            "Epoch 20: loss did not improve from 0.85282\n",
            "37/37 [==============================] - 21s 559ms/step - loss: 0.8561 - mae: 0.4451 - val_loss: 0.2396 - val_mae: 0.3256 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8502 - mae: 0.4423\n",
            "Epoch 21: loss improved from 0.85282 to 0.85024, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 591ms/step - loss: 0.8502 - mae: 0.4423 - val_loss: 0.2342 - val_mae: 0.3246 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8530 - mae: 0.4487\n",
            "Epoch 22: loss did not improve from 0.85024\n",
            "37/37 [==============================] - 23s 618ms/step - loss: 0.8530 - mae: 0.4487 - val_loss: 0.2538 - val_mae: 0.3356 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8500 - mae: 0.4420\n",
            "Epoch 23: loss improved from 0.85024 to 0.85002, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 21s 555ms/step - loss: 0.8500 - mae: 0.4420 - val_loss: 0.2357 - val_mae: 0.3186 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8504 - mae: 0.4436\n",
            "Epoch 24: loss did not improve from 0.85002\n",
            "37/37 [==============================] - 23s 626ms/step - loss: 0.8504 - mae: 0.4436 - val_loss: 0.2397 - val_mae: 0.3289 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8496 - mae: 0.4415\n",
            "Epoch 25: loss improved from 0.85002 to 0.84965, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 598ms/step - loss: 0.8496 - mae: 0.4415 - val_loss: 0.2419 - val_mae: 0.3498 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8507 - mae: 0.4444\n",
            "Epoch 26: loss did not improve from 0.84965\n",
            "37/37 [==============================] - 20s 555ms/step - loss: 0.8507 - mae: 0.4444 - val_loss: 0.2343 - val_mae: 0.3172 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8496 - mae: 0.4454\n",
            "Epoch 27: loss improved from 0.84965 to 0.84956, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 590ms/step - loss: 0.8496 - mae: 0.4454 - val_loss: 0.2362 - val_mae: 0.3172 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8467 - mae: 0.4398\n",
            "Epoch 28: loss improved from 0.84956 to 0.84669, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 603ms/step - loss: 0.8467 - mae: 0.4398 - val_loss: 0.2355 - val_mae: 0.3140 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8456 - mae: 0.4390\n",
            "Epoch 29: loss improved from 0.84669 to 0.84560, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 21s 559ms/step - loss: 0.8456 - mae: 0.4390 - val_loss: 0.2362 - val_mae: 0.3378 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8490 - mae: 0.4469\n",
            "Epoch 30: loss did not improve from 0.84560\n",
            "37/37 [==============================] - 22s 588ms/step - loss: 0.8490 - mae: 0.4469 - val_loss: 0.2430 - val_mae: 0.3152 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8466 - mae: 0.4418\n",
            "Epoch 31: loss did not improve from 0.84560\n",
            "37/37 [==============================] - 22s 599ms/step - loss: 0.8466 - mae: 0.4418 - val_loss: 0.2361 - val_mae: 0.3170 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8533 - mae: 0.4463\n",
            "Epoch 32: loss did not improve from 0.84560\n",
            "37/37 [==============================] - 21s 559ms/step - loss: 0.8533 - mae: 0.4463 - val_loss: 0.2344 - val_mae: 0.3196 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8491 - mae: 0.4473\n",
            "Epoch 33: loss did not improve from 0.84560\n",
            "37/37 [==============================] - 22s 600ms/step - loss: 0.8491 - mae: 0.4473 - val_loss: 0.2292 - val_mae: 0.3174 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8412 - mae: 0.4335\n",
            "Epoch 34: loss improved from 0.84560 to 0.84115, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 23s 627ms/step - loss: 0.8412 - mae: 0.4335 - val_loss: 0.2362 - val_mae: 0.3142 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8430 - mae: 0.4348\n",
            "Epoch 35: loss did not improve from 0.84115\n",
            "37/37 [==============================] - 22s 591ms/step - loss: 0.8430 - mae: 0.4348 - val_loss: 0.2324 - val_mae: 0.3281 - lr: 0.0010\n",
            "Epoch 36/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8424 - mae: 0.4407\n",
            "Epoch 36: loss did not improve from 0.84115\n",
            "37/37 [==============================] - 22s 576ms/step - loss: 0.8424 - mae: 0.4407 - val_loss: 0.2339 - val_mae: 0.3142 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8444 - mae: 0.4375\n",
            "Epoch 37: loss did not improve from 0.84115\n",
            "37/37 [==============================] - 23s 628ms/step - loss: 0.8444 - mae: 0.4375 - val_loss: 0.2287 - val_mae: 0.3282 - lr: 0.0010\n",
            "Epoch 38/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8390 - mae: 0.4389\n",
            "Epoch 38: loss improved from 0.84115 to 0.83904, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 608ms/step - loss: 0.8390 - mae: 0.4389 - val_loss: 0.2493 - val_mae: 0.3237 - lr: 0.0010\n",
            "Epoch 39/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8393 - mae: 0.4339\n",
            "Epoch 39: loss did not improve from 0.83904\n",
            "37/37 [==============================] - 22s 606ms/step - loss: 0.8393 - mae: 0.4339 - val_loss: 0.2353 - val_mae: 0.3110 - lr: 0.0010\n",
            "Epoch 40/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8404 - mae: 0.4331\n",
            "Epoch 40: loss did not improve from 0.83904\n",
            "37/37 [==============================] - 22s 595ms/step - loss: 0.8404 - mae: 0.4331 - val_loss: 0.2331 - val_mae: 0.3145 - lr: 0.0010\n",
            "Epoch 41/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8362 - mae: 0.4311\n",
            "Epoch 41: loss improved from 0.83904 to 0.83622, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 595ms/step - loss: 0.8362 - mae: 0.4311 - val_loss: 0.2325 - val_mae: 0.3255 - lr: 0.0010\n",
            "Epoch 42/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8359 - mae: 0.4367\n",
            "Epoch 42: loss improved from 0.83622 to 0.83589, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 21s 566ms/step - loss: 0.8359 - mae: 0.4367 - val_loss: 0.2442 - val_mae: 0.3135 - lr: 0.0010\n",
            "Epoch 43/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8371 - mae: 0.4327\n",
            "Epoch 43: loss did not improve from 0.83589\n",
            "37/37 [==============================] - 23s 632ms/step - loss: 0.8371 - mae: 0.4327 - val_loss: 0.2295 - val_mae: 0.3270 - lr: 0.0010\n",
            "Epoch 44/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8348 - mae: 0.4328\n",
            "Epoch 44: loss improved from 0.83589 to 0.83485, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 597ms/step - loss: 0.8348 - mae: 0.4328 - val_loss: 0.2294 - val_mae: 0.3322 - lr: 0.0010\n",
            "Epoch 45/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8340 - mae: 0.4315\n",
            "Epoch 45: loss improved from 0.83485 to 0.83402, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 24s 646ms/step - loss: 0.8340 - mae: 0.4315 - val_loss: 0.2303 - val_mae: 0.3220 - lr: 0.0010\n",
            "Epoch 46/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8359 - mae: 0.4301\n",
            "Epoch 46: loss did not improve from 0.83402\n",
            "37/37 [==============================] - 22s 597ms/step - loss: 0.8359 - mae: 0.4301 - val_loss: 0.2305 - val_mae: 0.3337 - lr: 0.0010\n",
            "Epoch 47/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8321 - mae: 0.4273\n",
            "Epoch 47: loss improved from 0.83402 to 0.83209, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 21s 573ms/step - loss: 0.8321 - mae: 0.4273 - val_loss: 0.2276 - val_mae: 0.3131 - lr: 0.0010\n",
            "Epoch 48/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8366 - mae: 0.4333\n",
            "Epoch 48: loss did not improve from 0.83209\n",
            "37/37 [==============================] - 24s 644ms/step - loss: 0.8366 - mae: 0.4333 - val_loss: 0.2289 - val_mae: 0.3167 - lr: 0.0010\n",
            "Epoch 49/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8320 - mae: 0.4273\n",
            "Epoch 49: loss improved from 0.83209 to 0.83197, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 605ms/step - loss: 0.8320 - mae: 0.4273 - val_loss: 0.2315 - val_mae: 0.3204 - lr: 0.0010\n",
            "Epoch 50/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8353 - mae: 0.4305\n",
            "Epoch 50: loss did not improve from 0.83197\n",
            "37/37 [==============================] - 22s 600ms/step - loss: 0.8353 - mae: 0.4305 - val_loss: 0.2288 - val_mae: 0.3237 - lr: 0.0010\n",
            "Epoch 51/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8296 - mae: 0.4239\n",
            "Epoch 51: loss improved from 0.83197 to 0.82960, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 594ms/step - loss: 0.8296 - mae: 0.4239 - val_loss: 0.2364 - val_mae: 0.3162 - lr: 0.0010\n",
            "Epoch 52/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8505 - mae: 0.4391\n",
            "Epoch 52: loss did not improve from 0.82960\n",
            "37/37 [==============================] - 22s 596ms/step - loss: 0.8505 - mae: 0.4391 - val_loss: 0.2609 - val_mae: 0.3626 - lr: 0.0010\n",
            "Epoch 53/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8430 - mae: 0.4396\n",
            "Epoch 53: loss did not improve from 0.82960\n",
            "37/37 [==============================] - 22s 588ms/step - loss: 0.8430 - mae: 0.4396 - val_loss: 0.2378 - val_mae: 0.3210 - lr: 0.0010\n",
            "Epoch 54/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8367 - mae: 0.4337\n",
            "Epoch 54: loss did not improve from 0.82960\n",
            "37/37 [==============================] - 21s 552ms/step - loss: 0.8367 - mae: 0.4337 - val_loss: 0.2345 - val_mae: 0.3204 - lr: 0.0010\n",
            "Epoch 55/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8396 - mae: 0.4394\n",
            "Epoch 55: loss did not improve from 0.82960\n",
            "37/37 [==============================] - 23s 631ms/step - loss: 0.8396 - mae: 0.4394 - val_loss: 0.2371 - val_mae: 0.3141 - lr: 0.0010\n",
            "Epoch 56/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8319 - mae: 0.4237\n",
            "Epoch 56: loss did not improve from 0.82960\n",
            "37/37 [==============================] - 24s 643ms/step - loss: 0.8319 - mae: 0.4237 - val_loss: 0.2406 - val_mae: 0.3455 - lr: 0.0010\n",
            "Epoch 57/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8322 - mae: 0.4293\n",
            "Epoch 57: loss did not improve from 0.82960\n",
            "\n",
            "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "37/37 [==============================] - 20s 553ms/step - loss: 0.8322 - mae: 0.4293 - val_loss: 0.2381 - val_mae: 0.3168 - lr: 0.0010\n",
            "Epoch 58/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8284 - mae: 0.4206\n",
            "Epoch 58: loss improved from 0.82960 to 0.82839, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 581ms/step - loss: 0.8284 - mae: 0.4206 - val_loss: 0.2343 - val_mae: 0.3201 - lr: 1.0000e-04\n",
            "Epoch 59/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8251 - mae: 0.4220\n",
            "Epoch 59: loss improved from 0.82839 to 0.82510, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 23s 628ms/step - loss: 0.8251 - mae: 0.4220 - val_loss: 0.2347 - val_mae: 0.3203 - lr: 1.0000e-04\n",
            "Epoch 60/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8244 - mae: 0.4182\n",
            "Epoch 60: loss improved from 0.82510 to 0.82436, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 597ms/step - loss: 0.8244 - mae: 0.4182 - val_loss: 0.2356 - val_mae: 0.3211 - lr: 1.0000e-04\n",
            "Epoch 61/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8246 - mae: 0.4198\n",
            "Epoch 61: loss did not improve from 0.82436\n",
            "37/37 [==============================] - 21s 559ms/step - loss: 0.8246 - mae: 0.4198 - val_loss: 0.2355 - val_mae: 0.3225 - lr: 1.0000e-04\n",
            "Epoch 62/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8241 - mae: 0.4164\n",
            "Epoch 62: loss improved from 0.82436 to 0.82411, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 24s 642ms/step - loss: 0.8241 - mae: 0.4164 - val_loss: 0.2361 - val_mae: 0.3228 - lr: 1.0000e-04\n",
            "Epoch 63/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8254 - mae: 0.4198\n",
            "Epoch 63: loss did not improve from 0.82411\n",
            "37/37 [==============================] - 23s 634ms/step - loss: 0.8254 - mae: 0.4198 - val_loss: 0.2361 - val_mae: 0.3242 - lr: 1.0000e-04\n",
            "Epoch 64/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8247 - mae: 0.4194\n",
            "Epoch 64: loss did not improve from 0.82411\n",
            "37/37 [==============================] - 22s 590ms/step - loss: 0.8247 - mae: 0.4194 - val_loss: 0.2371 - val_mae: 0.3240 - lr: 1.0000e-04\n",
            "Epoch 65/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8236 - mae: 0.4170\n",
            "Epoch 65: loss improved from 0.82411 to 0.82358, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 23s 605ms/step - loss: 0.8236 - mae: 0.4170 - val_loss: 0.2364 - val_mae: 0.3234 - lr: 1.0000e-04\n",
            "Epoch 66/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8238 - mae: 0.4223\n",
            "Epoch 66: loss did not improve from 0.82358\n",
            "37/37 [==============================] - 24s 641ms/step - loss: 0.8238 - mae: 0.4223 - val_loss: 0.2358 - val_mae: 0.3251 - lr: 1.0000e-04\n",
            "Epoch 67/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8231 - mae: 0.4181\n",
            "Epoch 67: loss improved from 0.82358 to 0.82312, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 606ms/step - loss: 0.8231 - mae: 0.4181 - val_loss: 0.2373 - val_mae: 0.3232 - lr: 1.0000e-04\n",
            "Epoch 68/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8220 - mae: 0.4148\n",
            "Epoch 68: loss improved from 0.82312 to 0.82202, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 604ms/step - loss: 0.8220 - mae: 0.4148 - val_loss: 0.2374 - val_mae: 0.3246 - lr: 1.0000e-04\n",
            "Epoch 69/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8227 - mae: 0.4169\n",
            "Epoch 69: loss did not improve from 0.82202\n",
            "37/37 [==============================] - 21s 564ms/step - loss: 0.8227 - mae: 0.4169 - val_loss: 0.2368 - val_mae: 0.3265 - lr: 1.0000e-04\n",
            "Epoch 70/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8230 - mae: 0.4216\n",
            "Epoch 70: loss did not improve from 0.82202\n",
            "37/37 [==============================] - 22s 598ms/step - loss: 0.8230 - mae: 0.4216 - val_loss: 0.2378 - val_mae: 0.3246 - lr: 1.0000e-04\n",
            "Epoch 71/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8226 - mae: 0.4169\n",
            "Epoch 71: loss did not improve from 0.82202\n",
            "37/37 [==============================] - 22s 603ms/step - loss: 0.8226 - mae: 0.4169 - val_loss: 0.2382 - val_mae: 0.3263 - lr: 1.0000e-04\n",
            "Epoch 72/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8208 - mae: 0.4190\n",
            "Epoch 72: loss improved from 0.82202 to 0.82080, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 21s 569ms/step - loss: 0.8208 - mae: 0.4190 - val_loss: 0.2379 - val_mae: 0.3258 - lr: 1.0000e-04\n",
            "Epoch 73/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8210 - mae: 0.4174\n",
            "Epoch 73: loss did not improve from 0.82080\n",
            "37/37 [==============================] - 23s 637ms/step - loss: 0.8210 - mae: 0.4174 - val_loss: 0.2383 - val_mae: 0.3261 - lr: 1.0000e-04\n",
            "Epoch 74/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8204 - mae: 0.4188\n",
            "Epoch 74: loss improved from 0.82080 to 0.82037, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 23s 633ms/step - loss: 0.8204 - mae: 0.4188 - val_loss: 0.2385 - val_mae: 0.3261 - lr: 1.0000e-04\n",
            "Epoch 75/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8211 - mae: 0.4157\n",
            "Epoch 75: loss did not improve from 0.82037\n",
            "37/37 [==============================] - 22s 600ms/step - loss: 0.8211 - mae: 0.4157 - val_loss: 0.2395 - val_mae: 0.3264 - lr: 1.0000e-04\n",
            "Epoch 76/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8203 - mae: 0.4168\n",
            "Epoch 76: loss improved from 0.82037 to 0.82034, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 599ms/step - loss: 0.8203 - mae: 0.4168 - val_loss: 0.2390 - val_mae: 0.3284 - lr: 1.0000e-04\n",
            "Epoch 77/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8198 - mae: 0.4165\n",
            "Epoch 77: loss improved from 0.82034 to 0.81981, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 24s 645ms/step - loss: 0.8198 - mae: 0.4165 - val_loss: 0.2401 - val_mae: 0.3303 - lr: 1.0000e-04\n",
            "Epoch 78/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8205 - mae: 0.4153\n",
            "Epoch 78: loss did not improve from 0.81981\n",
            "37/37 [==============================] - 22s 598ms/step - loss: 0.8205 - mae: 0.4153 - val_loss: 0.2401 - val_mae: 0.3291 - lr: 1.0000e-04\n",
            "Epoch 79/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8205 - mae: 0.4182\n",
            "Epoch 79: loss did not improve from 0.81981\n",
            "37/37 [==============================] - 22s 606ms/step - loss: 0.8205 - mae: 0.4182 - val_loss: 0.2394 - val_mae: 0.3282 - lr: 1.0000e-04\n",
            "Epoch 80/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8192 - mae: 0.4143\n",
            "Epoch 80: loss improved from 0.81981 to 0.81922, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 21s 566ms/step - loss: 0.8192 - mae: 0.4143 - val_loss: 0.2401 - val_mae: 0.3291 - lr: 1.0000e-04\n",
            "Epoch 81/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8188 - mae: 0.4162\n",
            "Epoch 81: loss improved from 0.81922 to 0.81884, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 600ms/step - loss: 0.8188 - mae: 0.4162 - val_loss: 0.2408 - val_mae: 0.3286 - lr: 1.0000e-04\n",
            "Epoch 82/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8195 - mae: 0.4147\n",
            "Epoch 82: loss did not improve from 0.81884\n",
            "37/37 [==============================] - 22s 595ms/step - loss: 0.8195 - mae: 0.4147 - val_loss: 0.2410 - val_mae: 0.3299 - lr: 1.0000e-04\n",
            "Epoch 83/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8196 - mae: 0.4182\n",
            "Epoch 83: loss did not improve from 0.81884\n",
            "37/37 [==============================] - 22s 602ms/step - loss: 0.8196 - mae: 0.4182 - val_loss: 0.2410 - val_mae: 0.3318 - lr: 1.0000e-04\n",
            "Epoch 84/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8197 - mae: 0.4177\n",
            "Epoch 84: loss did not improve from 0.81884\n",
            "37/37 [==============================] - 22s 593ms/step - loss: 0.8197 - mae: 0.4177 - val_loss: 0.2422 - val_mae: 0.3297 - lr: 1.0000e-04\n",
            "Epoch 85/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8184 - mae: 0.4139\n",
            "Epoch 85: loss improved from 0.81884 to 0.81841, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 23s 631ms/step - loss: 0.8184 - mae: 0.4139 - val_loss: 0.2417 - val_mae: 0.3333 - lr: 1.0000e-04\n",
            "Epoch 86/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8180 - mae: 0.4144\n",
            "Epoch 86: loss improved from 0.81841 to 0.81796, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 584ms/step - loss: 0.8180 - mae: 0.4144 - val_loss: 0.2431 - val_mae: 0.3328 - lr: 1.0000e-04\n",
            "Epoch 87/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8190 - mae: 0.4162\n",
            "Epoch 87: loss did not improve from 0.81796\n",
            "37/37 [==============================] - 21s 568ms/step - loss: 0.8190 - mae: 0.4162 - val_loss: 0.2430 - val_mae: 0.3366 - lr: 1.0000e-04\n",
            "Epoch 88/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8193 - mae: 0.4168\n",
            "Epoch 88: loss did not improve from 0.81796\n",
            "37/37 [==============================] - 22s 593ms/step - loss: 0.8193 - mae: 0.4168 - val_loss: 0.2423 - val_mae: 0.3344 - lr: 1.0000e-04\n",
            "Epoch 89/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8177 - mae: 0.4149\n",
            "Epoch 89: loss improved from 0.81796 to 0.81772, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 23s 633ms/step - loss: 0.8177 - mae: 0.4149 - val_loss: 0.2435 - val_mae: 0.3307 - lr: 1.0000e-04\n",
            "Epoch 90/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8163 - mae: 0.4127\n",
            "Epoch 90: loss improved from 0.81772 to 0.81625, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 21s 571ms/step - loss: 0.8163 - mae: 0.4127 - val_loss: 0.2441 - val_mae: 0.3339 - lr: 1.0000e-04\n",
            "Epoch 91/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8178 - mae: 0.4125\n",
            "Epoch 91: loss did not improve from 0.81625\n",
            "37/37 [==============================] - 22s 599ms/step - loss: 0.8178 - mae: 0.4125 - val_loss: 0.2454 - val_mae: 0.3354 - lr: 1.0000e-04\n",
            "Epoch 92/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8168 - mae: 0.4178\n",
            "Epoch 92: loss did not improve from 0.81625\n",
            "37/37 [==============================] - 22s 605ms/step - loss: 0.8168 - mae: 0.4178 - val_loss: 0.2463 - val_mae: 0.3358 - lr: 1.0000e-04\n",
            "Epoch 93/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8159 - mae: 0.4106\n",
            "Epoch 93: loss improved from 0.81625 to 0.81591, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 21s 565ms/step - loss: 0.8159 - mae: 0.4106 - val_loss: 0.2448 - val_mae: 0.3338 - lr: 1.0000e-04\n",
            "Epoch 94/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8158 - mae: 0.4162\n",
            "Epoch 94: loss improved from 0.81591 to 0.81580, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 601ms/step - loss: 0.8158 - mae: 0.4162 - val_loss: 0.2470 - val_mae: 0.3314 - lr: 1.0000e-04\n",
            "Epoch 95/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8163 - mae: 0.4119\n",
            "Epoch 95: loss did not improve from 0.81580\n",
            "37/37 [==============================] - 22s 599ms/step - loss: 0.8163 - mae: 0.4119 - val_loss: 0.2474 - val_mae: 0.3372 - lr: 1.0000e-04\n",
            "Epoch 96/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8152 - mae: 0.4108\n",
            "Epoch 96: loss improved from 0.81580 to 0.81516, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 598ms/step - loss: 0.8152 - mae: 0.4108 - val_loss: 0.2485 - val_mae: 0.3361 - lr: 1.0000e-04\n",
            "Epoch 97/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8155 - mae: 0.4107\n",
            "Epoch 97: loss did not improve from 0.81516\n",
            "37/37 [==============================] - 22s 592ms/step - loss: 0.8155 - mae: 0.4107 - val_loss: 0.2494 - val_mae: 0.3386 - lr: 1.0000e-04\n",
            "Epoch 98/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8166 - mae: 0.4148\n",
            "Epoch 98: loss did not improve from 0.81516\n",
            "37/37 [==============================] - 22s 598ms/step - loss: 0.8166 - mae: 0.4148 - val_loss: 0.2497 - val_mae: 0.3362 - lr: 1.0000e-04\n",
            "Epoch 99/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8149 - mae: 0.4112\n",
            "Epoch 99: loss improved from 0.81516 to 0.81486, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 593ms/step - loss: 0.8149 - mae: 0.4112 - val_loss: 0.2512 - val_mae: 0.3389 - lr: 1.0000e-04\n",
            "Epoch 100/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8140 - mae: 0.4130\n",
            "Epoch 100: loss improved from 0.81486 to 0.81399, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 598ms/step - loss: 0.8140 - mae: 0.4130 - val_loss: 0.2506 - val_mae: 0.3433 - lr: 1.0000e-04\n",
            "Epoch 101/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8131 - mae: 0.4111\n",
            "Epoch 101: loss improved from 0.81399 to 0.81312, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 23s 635ms/step - loss: 0.8131 - mae: 0.4111 - val_loss: 0.2503 - val_mae: 0.3401 - lr: 1.0000e-04\n",
            "Epoch 102/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8129 - mae: 0.4073\n",
            "Epoch 102: loss improved from 0.81312 to 0.81295, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 23s 630ms/step - loss: 0.8129 - mae: 0.4073 - val_loss: 0.2508 - val_mae: 0.3449 - lr: 1.0000e-04\n",
            "Epoch 103/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8144 - mae: 0.4139\n",
            "Epoch 103: loss did not improve from 0.81295\n",
            "37/37 [==============================] - 21s 575ms/step - loss: 0.8144 - mae: 0.4139 - val_loss: 0.2528 - val_mae: 0.3457 - lr: 1.0000e-04\n",
            "Epoch 104/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8134 - mae: 0.4115\n",
            "Epoch 104: loss did not improve from 0.81295\n",
            "37/37 [==============================] - 22s 591ms/step - loss: 0.8134 - mae: 0.4115 - val_loss: 0.2522 - val_mae: 0.3427 - lr: 1.0000e-04\n",
            "Epoch 105/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8136 - mae: 0.4085\n",
            "Epoch 105: loss did not improve from 0.81295\n",
            "37/37 [==============================] - 24s 641ms/step - loss: 0.8136 - mae: 0.4085 - val_loss: 0.2557 - val_mae: 0.3482 - lr: 1.0000e-04\n",
            "Epoch 106/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8138 - mae: 0.4105\n",
            "Epoch 106: loss did not improve from 0.81295\n",
            "37/37 [==============================] - 24s 650ms/step - loss: 0.8138 - mae: 0.4105 - val_loss: 0.2553 - val_mae: 0.3452 - lr: 1.0000e-04\n",
            "Epoch 107/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8117 - mae: 0.4100\n",
            "Epoch 107: loss improved from 0.81295 to 0.81172, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 602ms/step - loss: 0.8117 - mae: 0.4100 - val_loss: 0.2550 - val_mae: 0.3431 - lr: 1.0000e-04\n",
            "Epoch 108/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8117 - mae: 0.4102\n",
            "Epoch 108: loss improved from 0.81172 to 0.81172, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 21s 563ms/step - loss: 0.8117 - mae: 0.4102 - val_loss: 0.2557 - val_mae: 0.3420 - lr: 1.0000e-04\n",
            "Epoch 109/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8116 - mae: 0.4081\n",
            "Epoch 109: loss improved from 0.81172 to 0.81156, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 604ms/step - loss: 0.8116 - mae: 0.4081 - val_loss: 0.2551 - val_mae: 0.3427 - lr: 1.0000e-04\n",
            "Epoch 110/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8103 - mae: 0.4084\n",
            "Epoch 110: loss improved from 0.81156 to 0.81030, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 603ms/step - loss: 0.8103 - mae: 0.4084 - val_loss: 0.2580 - val_mae: 0.3466 - lr: 1.0000e-04\n",
            "Epoch 111/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8119 - mae: 0.4064\n",
            "Epoch 111: loss did not improve from 0.81030\n",
            "37/37 [==============================] - 22s 598ms/step - loss: 0.8119 - mae: 0.4064 - val_loss: 0.2589 - val_mae: 0.3482 - lr: 1.0000e-04\n",
            "Epoch 112/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8119 - mae: 0.4096\n",
            "Epoch 112: loss did not improve from 0.81030\n",
            "37/37 [==============================] - 22s 593ms/step - loss: 0.8119 - mae: 0.4096 - val_loss: 0.2596 - val_mae: 0.3490 - lr: 1.0000e-04\n",
            "Epoch 113/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8107 - mae: 0.4087\n",
            "Epoch 113: loss did not improve from 0.81030\n",
            "37/37 [==============================] - 22s 609ms/step - loss: 0.8107 - mae: 0.4087 - val_loss: 0.2597 - val_mae: 0.3510 - lr: 1.0000e-04\n",
            "Epoch 114/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8102 - mae: 0.4067\n",
            "Epoch 114: loss improved from 0.81030 to 0.81015, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 604ms/step - loss: 0.8102 - mae: 0.4067 - val_loss: 0.2612 - val_mae: 0.3475 - lr: 1.0000e-04\n",
            "Epoch 115/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8098 - mae: 0.4062\n",
            "Epoch 115: loss improved from 0.81015 to 0.80976, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 582ms/step - loss: 0.8098 - mae: 0.4062 - val_loss: 0.2630 - val_mae: 0.3546 - lr: 1.0000e-04\n",
            "Epoch 116/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8129 - mae: 0.4103\n",
            "Epoch 116: loss did not improve from 0.80976\n",
            "37/37 [==============================] - 23s 637ms/step - loss: 0.8129 - mae: 0.4103 - val_loss: 0.2625 - val_mae: 0.3492 - lr: 1.0000e-04\n",
            "Epoch 117/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8099 - mae: 0.4087\n",
            "Epoch 117: loss did not improve from 0.80976\n",
            "37/37 [==============================] - 22s 598ms/step - loss: 0.8099 - mae: 0.4087 - val_loss: 0.2637 - val_mae: 0.3526 - lr: 1.0000e-04\n",
            "Epoch 118/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8087 - mae: 0.4081\n",
            "Epoch 118: loss improved from 0.80976 to 0.80865, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 21s 558ms/step - loss: 0.8087 - mae: 0.4081 - val_loss: 0.2644 - val_mae: 0.3499 - lr: 1.0000e-04\n",
            "Epoch 119/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8089 - mae: 0.4073\n",
            "Epoch 119: loss did not improve from 0.80865\n",
            "37/37 [==============================] - 22s 591ms/step - loss: 0.8089 - mae: 0.4073 - val_loss: 0.2679 - val_mae: 0.3548 - lr: 1.0000e-04\n",
            "Epoch 120/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8093 - mae: 0.4054\n",
            "Epoch 120: loss did not improve from 0.80865\n",
            "37/37 [==============================] - 22s 604ms/step - loss: 0.8093 - mae: 0.4054 - val_loss: 0.2674 - val_mae: 0.3523 - lr: 1.0000e-04\n",
            "Epoch 121/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8098 - mae: 0.4067\n",
            "Epoch 121: loss did not improve from 0.80865\n",
            "37/37 [==============================] - 21s 565ms/step - loss: 0.8098 - mae: 0.4067 - val_loss: 0.2684 - val_mae: 0.3484 - lr: 1.0000e-04\n",
            "Epoch 122/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8079 - mae: 0.4022\n",
            "Epoch 122: loss improved from 0.80865 to 0.80789, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 23s 626ms/step - loss: 0.8079 - mae: 0.4022 - val_loss: 0.2687 - val_mae: 0.3577 - lr: 1.0000e-04\n",
            "Epoch 123/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8067 - mae: 0.4076\n",
            "Epoch 123: loss improved from 0.80789 to 0.80672, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 590ms/step - loss: 0.8067 - mae: 0.4076 - val_loss: 0.2735 - val_mae: 0.3523 - lr: 1.0000e-04\n",
            "Epoch 124/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8086 - mae: 0.4035\n",
            "Epoch 124: loss did not improve from 0.80672\n",
            "37/37 [==============================] - 21s 558ms/step - loss: 0.8086 - mae: 0.4035 - val_loss: 0.2637 - val_mae: 0.3534 - lr: 1.0000e-04\n",
            "Epoch 125/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8072 - mae: 0.4060\n",
            "Epoch 125: loss did not improve from 0.80672\n",
            "37/37 [==============================] - 23s 625ms/step - loss: 0.8072 - mae: 0.4060 - val_loss: 0.2715 - val_mae: 0.3555 - lr: 1.0000e-04\n",
            "Epoch 126/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8071 - mae: 0.4035\n",
            "Epoch 126: loss did not improve from 0.80672\n",
            "37/37 [==============================] - 22s 588ms/step - loss: 0.8071 - mae: 0.4035 - val_loss: 0.2740 - val_mae: 0.3621 - lr: 1.0000e-04\n",
            "Epoch 127/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8060 - mae: 0.4032\n",
            "Epoch 127: loss improved from 0.80672 to 0.80603, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 598ms/step - loss: 0.8060 - mae: 0.4032 - val_loss: 0.2681 - val_mae: 0.3530 - lr: 1.0000e-04\n",
            "Epoch 128/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8065 - mae: 0.4054\n",
            "Epoch 128: loss did not improve from 0.80603\n",
            "37/37 [==============================] - 21s 564ms/step - loss: 0.8065 - mae: 0.4054 - val_loss: 0.2774 - val_mae: 0.3635 - lr: 1.0000e-04\n",
            "Epoch 129/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8055 - mae: 0.4005\n",
            "Epoch 129: loss improved from 0.80603 to 0.80546, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 601ms/step - loss: 0.8055 - mae: 0.4005 - val_loss: 0.2749 - val_mae: 0.3613 - lr: 1.0000e-04\n",
            "Epoch 130/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8045 - mae: 0.4011\n",
            "Epoch 130: loss improved from 0.80546 to 0.80446, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 602ms/step - loss: 0.8045 - mae: 0.4011 - val_loss: 0.2856 - val_mae: 0.3761 - lr: 1.0000e-04\n",
            "Epoch 131/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8089 - mae: 0.4054\n",
            "Epoch 131: loss did not improve from 0.80446\n",
            "37/37 [==============================] - 21s 565ms/step - loss: 0.8089 - mae: 0.4054 - val_loss: 0.2753 - val_mae: 0.3651 - lr: 1.0000e-04\n",
            "Epoch 132/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8046 - mae: 0.4050\n",
            "Epoch 132: loss did not improve from 0.80446\n",
            "37/37 [==============================] - 22s 601ms/step - loss: 0.8046 - mae: 0.4050 - val_loss: 0.2781 - val_mae: 0.3622 - lr: 1.0000e-04\n",
            "Epoch 133/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8046 - mae: 0.4023\n",
            "Epoch 133: loss did not improve from 0.80446\n",
            "37/37 [==============================] - 23s 620ms/step - loss: 0.8046 - mae: 0.4023 - val_loss: 0.2849 - val_mae: 0.3664 - lr: 1.0000e-04\n",
            "Epoch 134/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8045 - mae: 0.4018\n",
            "Epoch 134: loss improved from 0.80446 to 0.80446, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 23s 630ms/step - loss: 0.8045 - mae: 0.4018 - val_loss: 0.2805 - val_mae: 0.3601 - lr: 1.0000e-04\n",
            "Epoch 135/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8044 - mae: 0.4025\n",
            "Epoch 135: loss improved from 0.80446 to 0.80443, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 604ms/step - loss: 0.8044 - mae: 0.4025 - val_loss: 0.2827 - val_mae: 0.3662 - lr: 1.0000e-04\n",
            "Epoch 136/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8040 - mae: 0.4020\n",
            "Epoch 136: loss improved from 0.80443 to 0.80403, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 24s 646ms/step - loss: 0.8040 - mae: 0.4020 - val_loss: 0.2862 - val_mae: 0.3656 - lr: 1.0000e-04\n",
            "Epoch 137/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8046 - mae: 0.3990\n",
            "Epoch 137: loss did not improve from 0.80403\n",
            "37/37 [==============================] - 22s 598ms/step - loss: 0.8046 - mae: 0.3990 - val_loss: 0.2809 - val_mae: 0.3630 - lr: 1.0000e-04\n",
            "Epoch 138/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8029 - mae: 0.4012\n",
            "Epoch 138: loss improved from 0.80403 to 0.80290, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 599ms/step - loss: 0.8029 - mae: 0.4012 - val_loss: 0.2775 - val_mae: 0.3575 - lr: 1.0000e-04\n",
            "Epoch 139/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8038 - mae: 0.4031\n",
            "Epoch 139: loss did not improve from 0.80290\n",
            "37/37 [==============================] - 21s 560ms/step - loss: 0.8038 - mae: 0.4031 - val_loss: 0.2835 - val_mae: 0.3667 - lr: 1.0000e-04\n",
            "Epoch 140/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8036 - mae: 0.4005\n",
            "Epoch 140: loss did not improve from 0.80290\n",
            "37/37 [==============================] - 23s 635ms/step - loss: 0.8036 - mae: 0.4005 - val_loss: 0.2863 - val_mae: 0.3710 - lr: 1.0000e-04\n",
            "Epoch 141/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8027 - mae: 0.4029\n",
            "Epoch 141: loss improved from 0.80290 to 0.80268, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 24s 645ms/step - loss: 0.8027 - mae: 0.4029 - val_loss: 0.2865 - val_mae: 0.3731 - lr: 1.0000e-04\n",
            "Epoch 142/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8008 - mae: 0.3990\n",
            "Epoch 142: loss improved from 0.80268 to 0.80080, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 589ms/step - loss: 0.8008 - mae: 0.3990 - val_loss: 0.2984 - val_mae: 0.3823 - lr: 1.0000e-04\n",
            "Epoch 143/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8015 - mae: 0.4004\n",
            "Epoch 143: loss did not improve from 0.80080\n",
            "37/37 [==============================] - 21s 568ms/step - loss: 0.8015 - mae: 0.4004 - val_loss: 0.3056 - val_mae: 0.3868 - lr: 1.0000e-04\n",
            "Epoch 144/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8018 - mae: 0.3980\n",
            "Epoch 144: loss did not improve from 0.80080\n",
            "37/37 [==============================] - 22s 599ms/step - loss: 0.8018 - mae: 0.3980 - val_loss: 0.2944 - val_mae: 0.3768 - lr: 1.0000e-04\n",
            "Epoch 145/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8010 - mae: 0.4009\n",
            "Epoch 145: loss did not improve from 0.80080\n",
            "37/37 [==============================] - 23s 631ms/step - loss: 0.8010 - mae: 0.4009 - val_loss: 0.2911 - val_mae: 0.3734 - lr: 1.0000e-04\n",
            "Epoch 146/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8011 - mae: 0.3992\n",
            "Epoch 146: loss did not improve from 0.80080\n",
            "37/37 [==============================] - 21s 564ms/step - loss: 0.8011 - mae: 0.3992 - val_loss: 0.2831 - val_mae: 0.3634 - lr: 1.0000e-04\n",
            "Epoch 147/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8006 - mae: 0.3974\n",
            "Epoch 147: loss improved from 0.80080 to 0.80057, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 24s 641ms/step - loss: 0.8006 - mae: 0.3974 - val_loss: 0.2939 - val_mae: 0.3731 - lr: 1.0000e-04\n",
            "Epoch 148/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8019 - mae: 0.3991\n",
            "Epoch 148: loss did not improve from 0.80057\n",
            "37/37 [==============================] - 22s 594ms/step - loss: 0.8019 - mae: 0.3991 - val_loss: 0.2967 - val_mae: 0.3806 - lr: 1.0000e-04\n",
            "Epoch 149/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8031 - mae: 0.4039\n",
            "Epoch 149: loss did not improve from 0.80057\n",
            "37/37 [==============================] - 22s 602ms/step - loss: 0.8031 - mae: 0.4039 - val_loss: 0.3036 - val_mae: 0.3813 - lr: 1.0000e-04\n",
            "Epoch 150/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7996 - mae: 0.3992\n",
            "Epoch 150: loss improved from 0.80057 to 0.79962, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 23s 616ms/step - loss: 0.7996 - mae: 0.3992 - val_loss: 0.2948 - val_mae: 0.3752 - lr: 1.0000e-04\n",
            "Epoch 151/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7999 - mae: 0.4010\n",
            "Epoch 151: loss did not improve from 0.79962\n",
            "37/37 [==============================] - 22s 592ms/step - loss: 0.7999 - mae: 0.4010 - val_loss: 0.2931 - val_mae: 0.3741 - lr: 1.0000e-04\n",
            "Epoch 152/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8002 - mae: 0.3987\n",
            "Epoch 152: loss did not improve from 0.79962\n",
            "37/37 [==============================] - 22s 593ms/step - loss: 0.8002 - mae: 0.3987 - val_loss: 0.2986 - val_mae: 0.3822 - lr: 1.0000e-04\n",
            "Epoch 153/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7982 - mae: 0.3975\n",
            "Epoch 153: loss improved from 0.79962 to 0.79820, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 21s 566ms/step - loss: 0.7982 - mae: 0.3975 - val_loss: 0.3036 - val_mae: 0.3866 - lr: 1.0000e-04\n",
            "Epoch 154/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8003 - mae: 0.3985\n",
            "Epoch 154: loss did not improve from 0.79820\n",
            "37/37 [==============================] - 22s 588ms/step - loss: 0.8003 - mae: 0.3985 - val_loss: 0.2982 - val_mae: 0.3811 - lr: 1.0000e-04\n",
            "Epoch 155/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7993 - mae: 0.4020\n",
            "Epoch 155: loss did not improve from 0.79820\n",
            "37/37 [==============================] - 23s 620ms/step - loss: 0.7993 - mae: 0.4020 - val_loss: 0.2893 - val_mae: 0.3653 - lr: 1.0000e-04\n",
            "Epoch 156/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7978 - mae: 0.3963\n",
            "Epoch 156: loss improved from 0.79820 to 0.79776, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 606ms/step - loss: 0.7978 - mae: 0.3963 - val_loss: 0.3084 - val_mae: 0.3932 - lr: 1.0000e-04\n",
            "Epoch 157/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7971 - mae: 0.3963\n",
            "Epoch 157: loss improved from 0.79776 to 0.79712, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 604ms/step - loss: 0.7971 - mae: 0.3963 - val_loss: 0.3081 - val_mae: 0.3928 - lr: 1.0000e-04\n",
            "Epoch 158/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7991 - mae: 0.3993\n",
            "Epoch 158: loss did not improve from 0.79712\n",
            "37/37 [==============================] - 22s 596ms/step - loss: 0.7991 - mae: 0.3993 - val_loss: 0.3083 - val_mae: 0.3879 - lr: 1.0000e-04\n",
            "Epoch 159/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7972 - mae: 0.3967\n",
            "Epoch 159: loss did not improve from 0.79712\n",
            "37/37 [==============================] - 21s 562ms/step - loss: 0.7972 - mae: 0.3967 - val_loss: 0.2981 - val_mae: 0.3771 - lr: 1.0000e-04\n",
            "Epoch 160/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7950 - mae: 0.3918\n",
            "Epoch 160: loss improved from 0.79712 to 0.79500, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 592ms/step - loss: 0.7950 - mae: 0.3918 - val_loss: 0.3097 - val_mae: 0.3945 - lr: 1.0000e-04\n",
            "Epoch 161/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7967 - mae: 0.4005\n",
            "Epoch 161: loss did not improve from 0.79500\n",
            "37/37 [==============================] - 22s 600ms/step - loss: 0.7967 - mae: 0.4005 - val_loss: 0.3115 - val_mae: 0.3886 - lr: 1.0000e-04\n",
            "Epoch 162/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7956 - mae: 0.3935\n",
            "Epoch 162: loss did not improve from 0.79500\n",
            "37/37 [==============================] - 21s 561ms/step - loss: 0.7956 - mae: 0.3935 - val_loss: 0.3017 - val_mae: 0.3782 - lr: 1.0000e-04\n",
            "Epoch 163/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7942 - mae: 0.3937\n",
            "Epoch 163: loss improved from 0.79500 to 0.79415, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 23s 639ms/step - loss: 0.7942 - mae: 0.3937 - val_loss: 0.3162 - val_mae: 0.3972 - lr: 1.0000e-04\n",
            "Epoch 164/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7951 - mae: 0.3923\n",
            "Epoch 164: loss did not improve from 0.79415\n",
            "37/37 [==============================] - 22s 607ms/step - loss: 0.7951 - mae: 0.3923 - val_loss: 0.3076 - val_mae: 0.3839 - lr: 1.0000e-04\n",
            "Epoch 165/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7959 - mae: 0.3936\n",
            "Epoch 165: loss did not improve from 0.79415\n",
            "37/37 [==============================] - 22s 609ms/step - loss: 0.7959 - mae: 0.3936 - val_loss: 0.3213 - val_mae: 0.3979 - lr: 1.0000e-04\n",
            "Epoch 166/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7933 - mae: 0.3920\n",
            "Epoch 166: loss improved from 0.79415 to 0.79326, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 21s 562ms/step - loss: 0.7933 - mae: 0.3920 - val_loss: 0.3266 - val_mae: 0.4053 - lr: 1.0000e-04\n",
            "Epoch 167/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7933 - mae: 0.3910\n",
            "Epoch 167: loss improved from 0.79326 to 0.79326, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 23s 628ms/step - loss: 0.7933 - mae: 0.3910 - val_loss: 0.3174 - val_mae: 0.3944 - lr: 1.0000e-04\n",
            "Epoch 168/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7951 - mae: 0.3963\n",
            "Epoch 168: loss did not improve from 0.79326\n",
            "37/37 [==============================] - 22s 596ms/step - loss: 0.7951 - mae: 0.3963 - val_loss: 0.3183 - val_mae: 0.3908 - lr: 1.0000e-04\n",
            "Epoch 169/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7939 - mae: 0.3925\n",
            "Epoch 169: loss did not improve from 0.79326\n",
            "37/37 [==============================] - 21s 564ms/step - loss: 0.7939 - mae: 0.3925 - val_loss: 0.3253 - val_mae: 0.3988 - lr: 1.0000e-04\n",
            "Epoch 170/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7925 - mae: 0.3933\n",
            "Epoch 170: loss improved from 0.79326 to 0.79254, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 597ms/step - loss: 0.7925 - mae: 0.3933 - val_loss: 0.3329 - val_mae: 0.4055 - lr: 1.0000e-04\n",
            "Epoch 171/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7939 - mae: 0.3907\n",
            "Epoch 171: loss did not improve from 0.79254\n",
            "37/37 [==============================] - 22s 595ms/step - loss: 0.7939 - mae: 0.3907 - val_loss: 0.3437 - val_mae: 0.4198 - lr: 1.0000e-04\n",
            "Epoch 172/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7940 - mae: 0.3953\n",
            "Epoch 172: loss did not improve from 0.79254\n",
            "37/37 [==============================] - 21s 563ms/step - loss: 0.7940 - mae: 0.3953 - val_loss: 0.3226 - val_mae: 0.3981 - lr: 1.0000e-04\n",
            "Epoch 173/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7922 - mae: 0.3938\n",
            "Epoch 173: loss improved from 0.79254 to 0.79221, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 594ms/step - loss: 0.7922 - mae: 0.3938 - val_loss: 0.3315 - val_mae: 0.3993 - lr: 1.0000e-04\n",
            "Epoch 174/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7928 - mae: 0.3925\n",
            "Epoch 174: loss did not improve from 0.79221\n",
            "37/37 [==============================] - 22s 595ms/step - loss: 0.7928 - mae: 0.3925 - val_loss: 0.3393 - val_mae: 0.4127 - lr: 1.0000e-04\n",
            "Epoch 175/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7930 - mae: 0.3908\n",
            "Epoch 175: loss did not improve from 0.79221\n",
            "37/37 [==============================] - 21s 562ms/step - loss: 0.7930 - mae: 0.3908 - val_loss: 0.3423 - val_mae: 0.4179 - lr: 1.0000e-04\n",
            "Epoch 176/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7938 - mae: 0.3953\n",
            "Epoch 176: loss did not improve from 0.79221\n",
            "37/37 [==============================] - 22s 592ms/step - loss: 0.7938 - mae: 0.3953 - val_loss: 0.3481 - val_mae: 0.4177 - lr: 1.0000e-04\n",
            "Epoch 177/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7921 - mae: 0.3933\n",
            "Epoch 177: loss improved from 0.79221 to 0.79215, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 600ms/step - loss: 0.7921 - mae: 0.3933 - val_loss: 0.3366 - val_mae: 0.4070 - lr: 1.0000e-04\n",
            "Epoch 178/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7921 - mae: 0.3930\n",
            "Epoch 178: loss improved from 0.79215 to 0.79205, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 21s 566ms/step - loss: 0.7921 - mae: 0.3930 - val_loss: 0.3371 - val_mae: 0.4093 - lr: 1.0000e-04\n",
            "Epoch 179/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7935 - mae: 0.3923\n",
            "Epoch 179: loss did not improve from 0.79205\n",
            "37/37 [==============================] - 24s 640ms/step - loss: 0.7935 - mae: 0.3923 - val_loss: 0.3344 - val_mae: 0.4050 - lr: 1.0000e-04\n",
            "Epoch 180/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7927 - mae: 0.3949\n",
            "Epoch 180: loss did not improve from 0.79205\n",
            "37/37 [==============================] - 22s 598ms/step - loss: 0.7927 - mae: 0.3949 - val_loss: 0.3428 - val_mae: 0.4117 - lr: 1.0000e-04\n",
            "Epoch 181/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7913 - mae: 0.3896\n",
            "Epoch 181: loss improved from 0.79205 to 0.79128, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 21s 577ms/step - loss: 0.7913 - mae: 0.3896 - val_loss: 0.3507 - val_mae: 0.4249 - lr: 1.0000e-04\n",
            "Epoch 182/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7903 - mae: 0.3911\n",
            "Epoch 182: loss improved from 0.79128 to 0.79027, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 573ms/step - loss: 0.7903 - mae: 0.3911 - val_loss: 0.3612 - val_mae: 0.4317 - lr: 1.0000e-04\n",
            "Epoch 183/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7905 - mae: 0.3921\n",
            "Epoch 183: loss did not improve from 0.79027\n",
            "37/37 [==============================] - 22s 597ms/step - loss: 0.7905 - mae: 0.3921 - val_loss: 0.3582 - val_mae: 0.4272 - lr: 1.0000e-04\n",
            "Epoch 184/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7921 - mae: 0.3916\n",
            "Epoch 184: loss did not improve from 0.79027\n",
            "37/37 [==============================] - 21s 583ms/step - loss: 0.7921 - mae: 0.3916 - val_loss: 0.3470 - val_mae: 0.4154 - lr: 1.0000e-04\n",
            "Epoch 185/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7896 - mae: 0.3896\n",
            "Epoch 185: loss improved from 0.79027 to 0.78961, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 574ms/step - loss: 0.7896 - mae: 0.3896 - val_loss: 0.3465 - val_mae: 0.4173 - lr: 1.0000e-04\n",
            "Epoch 186/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7885 - mae: 0.3877\n",
            "Epoch 186: loss improved from 0.78961 to 0.78851, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 599ms/step - loss: 0.7885 - mae: 0.3877 - val_loss: 0.3587 - val_mae: 0.4185 - lr: 1.0000e-04\n",
            "Epoch 187/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7906 - mae: 0.3905\n",
            "Epoch 187: loss did not improve from 0.78851\n",
            "37/37 [==============================] - 22s 590ms/step - loss: 0.7906 - mae: 0.3905 - val_loss: 0.3657 - val_mae: 0.4345 - lr: 1.0000e-04\n",
            "Epoch 188/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7882 - mae: 0.3893\n",
            "Epoch 188: loss improved from 0.78851 to 0.78820, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 21s 567ms/step - loss: 0.7882 - mae: 0.3893 - val_loss: 0.3584 - val_mae: 0.4300 - lr: 1.0000e-04\n",
            "Epoch 189/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7904 - mae: 0.3903\n",
            "Epoch 189: loss did not improve from 0.78820\n",
            "37/37 [==============================] - 24s 640ms/step - loss: 0.7904 - mae: 0.3903 - val_loss: 0.3540 - val_mae: 0.4191 - lr: 1.0000e-04\n",
            "Epoch 190/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7903 - mae: 0.3908\n",
            "Epoch 190: loss did not improve from 0.78820\n",
            "37/37 [==============================] - 24s 641ms/step - loss: 0.7903 - mae: 0.3908 - val_loss: 0.3499 - val_mae: 0.4200 - lr: 1.0000e-04\n",
            "Epoch 191/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7870 - mae: 0.3853\n",
            "Epoch 191: loss improved from 0.78820 to 0.78704, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 606ms/step - loss: 0.7870 - mae: 0.3853 - val_loss: 0.3672 - val_mae: 0.4344 - lr: 1.0000e-04\n",
            "Epoch 192/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7867 - mae: 0.3876\n",
            "Epoch 192: loss improved from 0.78704 to 0.78672, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 603ms/step - loss: 0.7867 - mae: 0.3876 - val_loss: 0.3778 - val_mae: 0.4435 - lr: 1.0000e-04\n",
            "Epoch 193/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7869 - mae: 0.3868\n",
            "Epoch 193: loss did not improve from 0.78672\n",
            "37/37 [==============================] - 23s 613ms/step - loss: 0.7869 - mae: 0.3868 - val_loss: 0.3667 - val_mae: 0.4299 - lr: 1.0000e-04\n",
            "Epoch 194/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7880 - mae: 0.3873\n",
            "Epoch 194: loss did not improve from 0.78672\n",
            "37/37 [==============================] - 22s 605ms/step - loss: 0.7880 - mae: 0.3873 - val_loss: 0.3635 - val_mae: 0.4279 - lr: 1.0000e-04\n",
            "Epoch 195/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7892 - mae: 0.3864\n",
            "Epoch 195: loss did not improve from 0.78672\n",
            "37/37 [==============================] - 22s 603ms/step - loss: 0.7892 - mae: 0.3864 - val_loss: 0.3514 - val_mae: 0.4181 - lr: 1.0000e-04\n",
            "Epoch 196/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7860 - mae: 0.3868\n",
            "Epoch 196: loss improved from 0.78672 to 0.78604, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 23s 606ms/step - loss: 0.7860 - mae: 0.3868 - val_loss: 0.3809 - val_mae: 0.4480 - lr: 1.0000e-04\n",
            "Epoch 197/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7870 - mae: 0.3839\n",
            "Epoch 197: loss did not improve from 0.78604\n",
            "37/37 [==============================] - 23s 613ms/step - loss: 0.7870 - mae: 0.3839 - val_loss: 0.3653 - val_mae: 0.4349 - lr: 1.0000e-04\n",
            "Epoch 198/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7882 - mae: 0.3877\n",
            "Epoch 198: loss did not improve from 0.78604\n",
            "37/37 [==============================] - 22s 608ms/step - loss: 0.7882 - mae: 0.3877 - val_loss: 0.4030 - val_mae: 0.4710 - lr: 1.0000e-04\n",
            "Epoch 199/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7894 - mae: 0.3889\n",
            "Epoch 199: loss did not improve from 0.78604\n",
            "37/37 [==============================] - 22s 600ms/step - loss: 0.7894 - mae: 0.3889 - val_loss: 0.3669 - val_mae: 0.4304 - lr: 1.0000e-04\n",
            "Epoch 200/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7867 - mae: 0.3858\n",
            "Epoch 200: loss did not improve from 0.78604\n",
            "37/37 [==============================] - 23s 607ms/step - loss: 0.7867 - mae: 0.3858 - val_loss: 0.3912 - val_mae: 0.4546 - lr: 1.0000e-04\n",
            "Epoch 201/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7866 - mae: 0.3870\n",
            "Epoch 201: loss did not improve from 0.78604\n",
            "37/37 [==============================] - 24s 648ms/step - loss: 0.7866 - mae: 0.3870 - val_loss: 0.3875 - val_mae: 0.4509 - lr: 1.0000e-04\n",
            "Epoch 202/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7870 - mae: 0.3892\n",
            "Epoch 202: loss did not improve from 0.78604\n",
            "\n",
            "Epoch 202: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "37/37 [==============================] - 22s 608ms/step - loss: 0.7870 - mae: 0.3892 - val_loss: 0.3734 - val_mae: 0.4225 - lr: 1.0000e-04\n",
            "Epoch 203/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7858 - mae: 0.3835\n",
            "Epoch 203: loss improved from 0.78604 to 0.78576, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 23s 627ms/step - loss: 0.7858 - mae: 0.3835 - val_loss: 0.3777 - val_mae: 0.4423 - lr: 1.0000e-04\n",
            "Epoch 204/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7838 - mae: 0.3848\n",
            "Epoch 204: loss improved from 0.78576 to 0.78384, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 23s 614ms/step - loss: 0.7838 - mae: 0.3848 - val_loss: 0.4084 - val_mae: 0.4652 - lr: 1.0000e-04\n",
            "Epoch 205/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7849 - mae: 0.3845\n",
            "Epoch 205: loss did not improve from 0.78384\n",
            "37/37 [==============================] - 22s 589ms/step - loss: 0.7849 - mae: 0.3845 - val_loss: 0.3563 - val_mae: 0.4080 - lr: 1.0000e-04\n",
            "Epoch 206/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7856 - mae: 0.3833\n",
            "Epoch 206: loss did not improve from 0.78384\n",
            "37/37 [==============================] - 22s 602ms/step - loss: 0.7856 - mae: 0.3833 - val_loss: 0.3821 - val_mae: 0.4464 - lr: 1.0000e-04\n",
            "Epoch 207/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7858 - mae: 0.3842\n",
            "Epoch 207: loss did not improve from 0.78384\n",
            "37/37 [==============================] - 22s 610ms/step - loss: 0.7858 - mae: 0.3842 - val_loss: 0.4034 - val_mae: 0.4635 - lr: 1.0000e-04\n",
            "Epoch 208/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7848 - mae: 0.3871\n",
            "Epoch 208: loss did not improve from 0.78384\n",
            "37/37 [==============================] - 22s 602ms/step - loss: 0.7848 - mae: 0.3871 - val_loss: 0.3794 - val_mae: 0.4414 - lr: 1.0000e-04\n",
            "Epoch 209/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7846 - mae: 0.3814\n",
            "Epoch 209: loss did not improve from 0.78384\n",
            "37/37 [==============================] - 24s 643ms/step - loss: 0.7846 - mae: 0.3814 - val_loss: 0.3718 - val_mae: 0.4303 - lr: 1.0000e-04\n",
            "Epoch 210/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7827 - mae: 0.3825\n",
            "Epoch 210: loss improved from 0.78384 to 0.78268, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 24s 655ms/step - loss: 0.7827 - mae: 0.3825 - val_loss: 0.3833 - val_mae: 0.4385 - lr: 1.0000e-04\n",
            "Epoch 211/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7852 - mae: 0.3870\n",
            "Epoch 211: loss did not improve from 0.78268\n",
            "37/37 [==============================] - 24s 660ms/step - loss: 0.7852 - mae: 0.3870 - val_loss: 0.3923 - val_mae: 0.4468 - lr: 1.0000e-04\n",
            "Epoch 212/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7846 - mae: 0.3831\n",
            "Epoch 212: loss did not improve from 0.78268\n",
            "37/37 [==============================] - 24s 648ms/step - loss: 0.7846 - mae: 0.3831 - val_loss: 0.3983 - val_mae: 0.4501 - lr: 1.0000e-04\n",
            "Epoch 213/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7843 - mae: 0.3845\n",
            "Epoch 213: loss did not improve from 0.78268\n",
            "37/37 [==============================] - 21s 565ms/step - loss: 0.7843 - mae: 0.3845 - val_loss: 0.4000 - val_mae: 0.4555 - lr: 1.0000e-04\n",
            "Epoch 214/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7853 - mae: 0.3859\n",
            "Epoch 214: loss did not improve from 0.78268\n",
            "37/37 [==============================] - 23s 629ms/step - loss: 0.7853 - mae: 0.3859 - val_loss: 0.4248 - val_mae: 0.4824 - lr: 1.0000e-04\n",
            "Epoch 215/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7858 - mae: 0.3880\n",
            "Epoch 215: loss did not improve from 0.78268\n",
            "37/37 [==============================] - 22s 592ms/step - loss: 0.7858 - mae: 0.3880 - val_loss: 0.4025 - val_mae: 0.4533 - lr: 1.0000e-04\n",
            "Epoch 216/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7841 - mae: 0.3852\n",
            "Epoch 216: loss did not improve from 0.78268\n",
            "37/37 [==============================] - 22s 597ms/step - loss: 0.7841 - mae: 0.3852 - val_loss: 0.3847 - val_mae: 0.4379 - lr: 1.0000e-04\n",
            "Epoch 217/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7814 - mae: 0.3808\n",
            "Epoch 217: loss improved from 0.78268 to 0.78138, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 598ms/step - loss: 0.7814 - mae: 0.3808 - val_loss: 0.4480 - val_mae: 0.4961 - lr: 1.0000e-04\n",
            "Epoch 218/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7819 - mae: 0.3827\n",
            "Epoch 218: loss did not improve from 0.78138\n",
            "37/37 [==============================] - 22s 595ms/step - loss: 0.7819 - mae: 0.3827 - val_loss: 0.4168 - val_mae: 0.4614 - lr: 1.0000e-04\n",
            "Epoch 219/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7844 - mae: 0.3837\n",
            "Epoch 219: loss did not improve from 0.78138\n",
            "37/37 [==============================] - 23s 633ms/step - loss: 0.7844 - mae: 0.3837 - val_loss: 0.3892 - val_mae: 0.4391 - lr: 1.0000e-04\n",
            "Epoch 220/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7833 - mae: 0.3815\n",
            "Epoch 220: loss did not improve from 0.78138\n",
            "37/37 [==============================] - 21s 574ms/step - loss: 0.7833 - mae: 0.3815 - val_loss: 0.3961 - val_mae: 0.4448 - lr: 1.0000e-04\n",
            "Epoch 221/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7817 - mae: 0.3785\n",
            "Epoch 221: loss did not improve from 0.78138\n",
            "37/37 [==============================] - 22s 584ms/step - loss: 0.7817 - mae: 0.3785 - val_loss: 0.4284 - val_mae: 0.4776 - lr: 1.0000e-04\n",
            "Epoch 222/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7811 - mae: 0.3802\n",
            "Epoch 222: loss improved from 0.78138 to 0.78111, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 610ms/step - loss: 0.7811 - mae: 0.3802 - val_loss: 0.4353 - val_mae: 0.4744 - lr: 1.0000e-04\n",
            "Epoch 223/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7802 - mae: 0.3794\n",
            "Epoch 223: loss improved from 0.78111 to 0.78018, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 606ms/step - loss: 0.7802 - mae: 0.3794 - val_loss: 0.4290 - val_mae: 0.4716 - lr: 1.0000e-04\n",
            "Epoch 224/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7799 - mae: 0.3793\n",
            "Epoch 224: loss improved from 0.78018 to 0.77987, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 585ms/step - loss: 0.7799 - mae: 0.3793 - val_loss: 0.4453 - val_mae: 0.4900 - lr: 1.0000e-04\n",
            "Epoch 225/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7827 - mae: 0.3823\n",
            "Epoch 225: loss did not improve from 0.77987\n",
            "37/37 [==============================] - 22s 602ms/step - loss: 0.7827 - mae: 0.3823 - val_loss: 0.4034 - val_mae: 0.4501 - lr: 1.0000e-04\n",
            "Epoch 226/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7788 - mae: 0.3809\n",
            "Epoch 226: loss improved from 0.77987 to 0.77878, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 21s 576ms/step - loss: 0.7788 - mae: 0.3809 - val_loss: 0.4722 - val_mae: 0.5085 - lr: 1.0000e-04\n",
            "Epoch 227/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7810 - mae: 0.3839\n",
            "Epoch 227: loss did not improve from 0.77878\n",
            "37/37 [==============================] - 21s 570ms/step - loss: 0.7810 - mae: 0.3839 - val_loss: 0.4551 - val_mae: 0.4925 - lr: 1.0000e-04\n",
            "Epoch 228/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7800 - mae: 0.3795\n",
            "Epoch 228: loss did not improve from 0.77878\n",
            "37/37 [==============================] - 22s 585ms/step - loss: 0.7800 - mae: 0.3795 - val_loss: 0.4308 - val_mae: 0.4746 - lr: 1.0000e-04\n",
            "Epoch 229/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7786 - mae: 0.3767\n",
            "Epoch 229: loss improved from 0.77878 to 0.77858, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 21s 567ms/step - loss: 0.7786 - mae: 0.3767 - val_loss: 0.4893 - val_mae: 0.5247 - lr: 1.0000e-04\n",
            "Epoch 230/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7791 - mae: 0.3798\n",
            "Epoch 230: loss did not improve from 0.77858\n",
            "37/37 [==============================] - 23s 603ms/step - loss: 0.7791 - mae: 0.3798 - val_loss: 0.4417 - val_mae: 0.4848 - lr: 1.0000e-04\n",
            "Epoch 231/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7830 - mae: 0.3855\n",
            "Epoch 231: loss did not improve from 0.77858\n",
            "37/37 [==============================] - 21s 582ms/step - loss: 0.7830 - mae: 0.3855 - val_loss: 0.4125 - val_mae: 0.4605 - lr: 1.0000e-04\n",
            "Epoch 232/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7778 - mae: 0.3792\n",
            "Epoch 232: loss improved from 0.77858 to 0.77785, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 22s 588ms/step - loss: 0.7778 - mae: 0.3792 - val_loss: 0.4518 - val_mae: 0.4859 - lr: 1.0000e-04\n",
            "Epoch 233/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7813 - mae: 0.3818\n",
            "Epoch 233: loss did not improve from 0.77785\n",
            "37/37 [==============================] - 20s 542ms/step - loss: 0.7813 - mae: 0.3818 - val_loss: 0.4239 - val_mae: 0.4670 - lr: 1.0000e-04\n",
            "Epoch 234/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7812 - mae: 0.3838\n",
            "Epoch 234: loss did not improve from 0.77785\n",
            "37/37 [==============================] - 21s 581ms/step - loss: 0.7812 - mae: 0.3838 - val_loss: 0.4420 - val_mae: 0.4765 - lr: 1.0000e-04\n",
            "Epoch 235/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7786 - mae: 0.3790\n",
            "Epoch 235: loss did not improve from 0.77785\n",
            "37/37 [==============================] - 21s 578ms/step - loss: 0.7786 - mae: 0.3790 - val_loss: 0.4299 - val_mae: 0.4666 - lr: 1.0000e-04\n",
            "Epoch 236/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7784 - mae: 0.3777\n",
            "Epoch 236: loss did not improve from 0.77785\n",
            "37/37 [==============================] - 21s 572ms/step - loss: 0.7784 - mae: 0.3777 - val_loss: 0.4381 - val_mae: 0.4765 - lr: 1.0000e-04\n",
            "Epoch 237/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7784 - mae: 0.3788\n",
            "Epoch 237: loss did not improve from 0.77785\n",
            "37/37 [==============================] - 21s 583ms/step - loss: 0.7784 - mae: 0.3788 - val_loss: 0.4697 - val_mae: 0.5064 - lr: 1.0000e-04\n",
            "Epoch 238/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7763 - mae: 0.3762\n",
            "Epoch 238: loss improved from 0.77785 to 0.77626, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 20s 548ms/step - loss: 0.7763 - mae: 0.3762 - val_loss: 0.4479 - val_mae: 0.4824 - lr: 1.0000e-04\n",
            "Epoch 239/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7775 - mae: 0.3777\n",
            "Epoch 239: loss did not improve from 0.77626\n",
            "37/37 [==============================] - 21s 582ms/step - loss: 0.7775 - mae: 0.3777 - val_loss: 0.4599 - val_mae: 0.4940 - lr: 1.0000e-04\n",
            "Epoch 240/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7767 - mae: 0.3752\n",
            "Epoch 240: loss did not improve from 0.77626\n",
            "37/37 [==============================] - 22s 594ms/step - loss: 0.7767 - mae: 0.3752 - val_loss: 0.4487 - val_mae: 0.4843 - lr: 1.0000e-04\n",
            "Epoch 241/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7748 - mae: 0.3729\n",
            "Epoch 241: loss improved from 0.77626 to 0.77483, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 20s 556ms/step - loss: 0.7748 - mae: 0.3729 - val_loss: 0.4716 - val_mae: 0.5035 - lr: 1.0000e-04\n",
            "Epoch 242/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7764 - mae: 0.3776\n",
            "Epoch 242: loss did not improve from 0.77483\n",
            "37/37 [==============================] - 22s 588ms/step - loss: 0.7764 - mae: 0.3776 - val_loss: 0.4754 - val_mae: 0.5038 - lr: 1.0000e-04\n",
            "Epoch 243/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7770 - mae: 0.3776\n",
            "Epoch 243: loss did not improve from 0.77483\n",
            "37/37 [==============================] - 22s 587ms/step - loss: 0.7770 - mae: 0.3776 - val_loss: 0.4854 - val_mae: 0.5130 - lr: 1.0000e-04\n",
            "Epoch 244/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7783 - mae: 0.3810\n",
            "Epoch 244: loss did not improve from 0.77483\n",
            "37/37 [==============================] - 20s 551ms/step - loss: 0.7783 - mae: 0.3810 - val_loss: 0.4544 - val_mae: 0.4861 - lr: 1.0000e-04\n",
            "Epoch 245/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7774 - mae: 0.3773\n",
            "Epoch 245: loss did not improve from 0.77483\n",
            "37/37 [==============================] - 22s 591ms/step - loss: 0.7774 - mae: 0.3773 - val_loss: 0.4446 - val_mae: 0.4771 - lr: 1.0000e-04\n",
            "Epoch 246/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7759 - mae: 0.3774\n",
            "Epoch 246: loss did not improve from 0.77483\n",
            "37/37 [==============================] - 21s 565ms/step - loss: 0.7759 - mae: 0.3774 - val_loss: 0.4409 - val_mae: 0.4725 - lr: 1.0000e-04\n",
            "Epoch 247/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7768 - mae: 0.3804\n",
            "Epoch 247: loss did not improve from 0.77483\n",
            "37/37 [==============================] - 22s 600ms/step - loss: 0.7768 - mae: 0.3804 - val_loss: 0.4746 - val_mae: 0.5024 - lr: 1.0000e-04\n",
            "Epoch 248/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7761 - mae: 0.3750\n",
            "Epoch 248: loss did not improve from 0.77483\n",
            "37/37 [==============================] - 22s 588ms/step - loss: 0.7761 - mae: 0.3750 - val_loss: 0.4467 - val_mae: 0.4809 - lr: 1.0000e-04\n",
            "Epoch 249/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7743 - mae: 0.3739\n",
            "Epoch 249: loss improved from 0.77483 to 0.77429, saving model to /content/best_model.h5\n",
            "37/37 [==============================] - 21s 583ms/step - loss: 0.7743 - mae: 0.3739 - val_loss: 0.4351 - val_mae: 0.4633 - lr: 1.0000e-04\n",
            "Epoch 250/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7794 - mae: 0.3783\n",
            "Epoch 250: loss did not improve from 0.77429\n",
            "37/37 [==============================] - 21s 558ms/step - loss: 0.7794 - mae: 0.3783 - val_loss: 0.4489 - val_mae: 0.4740 - lr: 1.0000e-04\n",
            "Epoch 251/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7765 - mae: 0.3753\n",
            "Epoch 251: loss did not improve from 0.77429\n",
            "37/37 [==============================] - 22s 594ms/step - loss: 0.7765 - mae: 0.3753 - val_loss: 0.4593 - val_mae: 0.4842 - lr: 1.0000e-04\n",
            "Epoch 252/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7760 - mae: 0.3769\n",
            "Epoch 252: loss did not improve from 0.77429\n",
            "37/37 [==============================] - 23s 623ms/step - loss: 0.7760 - mae: 0.3769 - val_loss: 0.4619 - val_mae: 0.4898 - lr: 1.0000e-04\n",
            "Epoch 253/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7748 - mae: 0.3783\n",
            "Epoch 253: loss did not improve from 0.77429\n",
            "37/37 [==============================] - 23s 617ms/step - loss: 0.7748 - mae: 0.3783 - val_loss: 0.4840 - val_mae: 0.5038 - lr: 1.0000e-04\n",
            "Epoch 254/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7746 - mae: 0.3765\n",
            "Epoch 254: loss did not improve from 0.77429\n",
            "37/37 [==============================] - 24s 646ms/step - loss: 0.7746 - mae: 0.3765 - val_loss: 0.4994 - val_mae: 0.5141 - lr: 1.0000e-04\n",
            "Epoch 255/500\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7765 - mae: 0.3744\n",
            "Epoch 255: loss did not improve from 0.77429\n",
            "The model has reached expected loss. \n",
            " akurasi : 0.78, akurasi validasi : 0.51. Proses learning dihentikan\n",
            "37/37 [==============================] - 24s 650ms/step - loss: 0.7765 - mae: 0.3744 - val_loss: 0.5077 - val_mae: 0.5228 - lr: 1.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Load and Evaluate The Best Model"
      ],
      "metadata": {
        "id": "WlcBodj08I82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fix_model = load_model('/content/best_model.h5')\n",
        "\n",
        "# evaluate the model\n",
        "mse, mae = fix_model.evaluate(test_features, test_targets)\n",
        "print('mse : ', mse)\n",
        "print('mae : ', mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qwVS5QatMMx",
        "outputId": "030c1006-6c02-45aa-a41d-7853d914a9b8"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 17s 269ms/step - loss: 0.2072 - mae: 0.2720\n",
            "mse :  0.20724961161613464\n",
            "mae :  0.27202749252319336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot learning history [ MSE ]\n",
        "plt.plot(history.history['loss'], label='MSE', color='r')\n",
        "plt.plot(history.history['val_loss'], label='val MSE', color='b')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MSE')\n",
        "plt.title('model learning loss (error)')\n",
        "plt.legend();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "WN7jv2Mn6uKs",
        "outputId": "b353b95a-b9a1-4897-9c83-0aa45fa5a35e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot learning history [ MAE ]\n",
        "plt.plot(history.history['mae'], label='MAE', color='r')\n",
        "plt.plot(history.history['val_mae'], label='val MAE', color='b')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MAE')\n",
        "plt.title('model learning loss (error)')\n",
        "plt.legend();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "xf0QkxDz7ISy",
        "outputId": "d4139831-dc83-4c32-aaf9-21fdf69f0831"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z8k2BPVp76Vb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
